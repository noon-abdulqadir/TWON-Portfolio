{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTN: This script should be run AFTER language detection is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop non-English job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_JOBS_RAW_LANGUAGE_DETECTED\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# df save sir\n",
    "df_save_dir = f'{data_dir}final dfs/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{df_save_dir}/df_jobs_raw_language_detected.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62577 entries, 0 to 62576\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     62577 non-null  object \n",
      " 1   Platform           62577 non-null  object \n",
      " 2   Job ID             62577 non-null  object \n",
      " 3   Job Title          62577 non-null  object \n",
      " 4   Company Name       62574 non-null  object \n",
      " 5   Location           62577 non-null  object \n",
      " 6   Job Description    62577 non-null  object \n",
      " 7   Rating             3975 non-null   float64\n",
      " 8   Employment Type    61995 non-null  object \n",
      " 9   Company URL        59263 non-null  object \n",
      " 10  Job URL            62577 non-null  object \n",
      " 11  Job Age            62577 non-null  object \n",
      " 12  Job Age Number     62577 non-null  object \n",
      " 13  Collection Date    62577 non-null  object \n",
      " 14  Data Row           58599 non-null  float64\n",
      " 15  Tracking ID        58599 non-null  object \n",
      " 16  Industry           59184 non-null  object \n",
      " 17  Job Date           58602 non-null  object \n",
      " 18  Type of ownership  582 non-null    object \n",
      " 19  Language           62577 non-null  object \n",
      "dtypes: float64(2), object(18)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nl              44863\n",
       "en              17591\n",
       "de                 53\n",
       "fr                 36\n",
       "['nl', 'en']        9\n",
       "['en', 'nl']        8\n",
       "pl                  5\n",
       "id                  4\n",
       "da                  4\n",
       "tr                  1\n",
       "['nl', 'af']        1\n",
       "st                  1\n",
       "af                  1\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nl = 44863, en = 17591, ['en', 'nl'] = 8\n",
    "df_jobs['Language'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The majority of ['en', 'nl'] labeled job descriptions contain mostly English\n",
    "df_jobs['Language'] = df_jobs['Language'].apply(\n",
    "    lambda lang: 'en' if lang == \"['en', 'nl']\" else lang\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-English ads\n",
    "df_jobs.drop(\n",
    "    df_jobs[\n",
    "        df_jobs['Language'] != 'en'\n",
    "    ].index, \n",
    "        axis='index', \n",
    "        inplace=True, \n",
    "        errors='ignore'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17599"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17599\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_raw_english_only.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_raw_english_only.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix abbreviations in job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_JOBS_RAW_ENGLISH_ONLY\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# df save sir\n",
    "df_save_dir = f'{data_dir}final dfs/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{df_save_dir}/df_jobs_raw_english_only.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17599 entries, 0 to 17598\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     17599 non-null  object \n",
      " 1   Platform           17599 non-null  object \n",
      " 2   Job ID             17599 non-null  object \n",
      " 3   Job Title          17599 non-null  object \n",
      " 4   Company Name       17597 non-null  object \n",
      " 5   Location           17599 non-null  object \n",
      " 6   Job Description    17599 non-null  object \n",
      " 7   Rating             3780 non-null   float64\n",
      " 8   Employment Type    17017 non-null  object \n",
      " 9   Company URL        15959 non-null  object \n",
      " 10  Job URL            17599 non-null  object \n",
      " 11  Job Age            17599 non-null  object \n",
      " 12  Job Age Number     17599 non-null  object \n",
      " 13  Collection Date    17599 non-null  object \n",
      " 14  Data Row           13816 non-null  float64\n",
      " 15  Tracking ID        13816 non-null  object \n",
      " 16  Industry           14401 non-null  object \n",
      " 17  Job Date           13819 non-null  object \n",
      " 18  Type of ownership  582 non-null    object \n",
      " 19  Language           17599 non-null  object \n",
      "dtypes: float64(2), object(18)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "    lambda job_description: ' '.join(job_description.split('/')) if '/' in job_description else job_description\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abb_dict = {\n",
    "    r'incl\\.': 'including', \n",
    "    r'e\\.g\\.': 'for example', \n",
    "    r'e\\.g': 'for example', \n",
    "    r'etc\\.': 'et cetera', \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs['Job Description'].replace(abb_dict, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_raw_fixed_abbreviations.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_raw_fixed_abbreviations.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add English and Dutch language requirement columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_JOBS_RAW_FIXED_ABBREVIATIONS\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# df save sir\n",
    "df_save_dir = f'{data_dir}final dfs/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{df_save_dir}/df_jobs_raw_fixed_abbreviations.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17599 entries, 0 to 17598\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     17599 non-null  object \n",
      " 1   Platform           17599 non-null  object \n",
      " 2   Job ID             17599 non-null  object \n",
      " 3   Job Title          17599 non-null  object \n",
      " 4   Company Name       17597 non-null  object \n",
      " 5   Location           17599 non-null  object \n",
      " 6   Job Description    17599 non-null  object \n",
      " 7   Rating             3780 non-null   float64\n",
      " 8   Employment Type    17017 non-null  object \n",
      " 9   Company URL        15959 non-null  object \n",
      " 10  Job URL            17599 non-null  object \n",
      " 11  Job Age            17599 non-null  object \n",
      " 12  Job Age Number     17599 non-null  object \n",
      " 13  Collection Date    17599 non-null  object \n",
      " 14  Data Row           13816 non-null  float64\n",
      " 15  Tracking ID        13816 non-null  object \n",
      " 16  Industry           14401 non-null  object \n",
      " 17  Job Date           13819 non-null  object \n",
      " 18  Type of ownership  582 non-null    object \n",
      " 19  Language           17599 non-null  object \n",
      "dtypes: float64(2), object(18)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add language requirement column\n",
    "# Use regex to find language requirement\n",
    "dutch_requirement_pattern = r'[Ll]anguage: [Dd]utch|[Dd]utch [Pp]referred|[Dd]utch [Re]quired|[Dd]utch [Ll]anguage|[Pp]roficient in [Dd]utch|[Ss]peak [Dd]utch|[Kk]now [Dd]utch'\n",
    "english_requirement_pattern = r'[Ll]anguage: [Ee]nglish|[Ee]nglish [Pp]referred|[Ee]nglish [Re]quired|[Ee]nglish [Ll]anguage|[Pp]roficient in [Ee]nglish|[Ss]peak [Ee]nglish|[Kk]now [Ee]nglish'\n",
    "\n",
    "lang_requirements = {\n",
    "    'Dutch Requirement': dutch_requirement_pattern, 'English Requirement': english_requirement_pattern\n",
    "}\n",
    "\n",
    "for lang_req, lang_req_pattern in lang_requirements.items():\n",
    "    \n",
    "    if lang_req in df_jobs.columns:\n",
    "        df_jobs.drop(columns=[lang_req], inplace=True)\n",
    "    df_jobs[lang_req] = np.where(\n",
    "        df_jobs['Job Description'].str.contains(lang_req_pattern),\n",
    "        'Yes',\n",
    "        'No',\n",
    "    )\n",
    "\n",
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_raw_language_requirement.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_raw_english_requirement.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     17364\n",
       "Yes      235\n",
       "Name: Dutch Requirement, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yes = 235\n",
    "df_jobs['Dutch Requirement'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     17073\n",
       "Yes      526\n",
       "Name: English Requirement, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yes = 526\n",
    "df_jobs['English Requirement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_raw_language_requirement.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_raw_language_requirement.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data from Sectors dataframe (see CBS directory under scrapped_data directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_JOBS_RAW_LANGUAGE_REQUIREMENT\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# df save sir\n",
    "df_save_dir = f'{data_dir}final dfs/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{df_save_dir}/df_jobs_raw_language_requirement.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17599 entries, 0 to 17598\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Search Keyword       17599 non-null  object \n",
      " 1   Platform             17599 non-null  object \n",
      " 2   Job ID               17599 non-null  object \n",
      " 3   Job Title            17599 non-null  object \n",
      " 4   Company Name         17597 non-null  object \n",
      " 5   Location             17599 non-null  object \n",
      " 6   Job Description      17599 non-null  object \n",
      " 7   Rating               3780 non-null   float64\n",
      " 8   Employment Type      17017 non-null  object \n",
      " 9   Company URL          15959 non-null  object \n",
      " 10  Job URL              17599 non-null  object \n",
      " 11  Job Age              17599 non-null  object \n",
      " 12  Job Age Number       17599 non-null  object \n",
      " 13  Collection Date      17599 non-null  object \n",
      " 14  Data Row             13816 non-null  float64\n",
      " 15  Tracking ID          13816 non-null  object \n",
      " 16  Industry             14401 non-null  object \n",
      " 17  Job Date             13819 non-null  object \n",
      " 18  Type of ownership    582 non-null    object \n",
      " 19  Language             17599 non-null  object \n",
      " 20  Dutch Requirement    17599 non-null  object \n",
      " 21  English Requirement  17599 non-null  object \n",
      "dtypes: float64(2), object(20)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors = pd.read_pickle(f'{scraped_data}CBS/Data/Sectors Output from script.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            ('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            ('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            ('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            ('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            ('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            ('SBI Sector Titles', 'Industry class / branch (SIC2008)', ...),\n",
       "            (           'Gender',                            'Female', ...),\n",
       "            (           'Gender',                            'Female', ...),\n",
       "            (           'Gender',                            'Female', ...),\n",
       "            (           'Gender',                            'Female', ...),\n",
       "            (           'Gender',                              'Male', ...),\n",
       "            (           'Gender',                              'Male', ...),\n",
       "            (           'Gender',                              'Male', ...),\n",
       "            (           'Gender',                              'Male', ...),\n",
       "            (           'Gender',       'Sectoral Gender Segregation', ...),\n",
       "            (              'Age',               'Older (>= 45 years)', ...),\n",
       "            (              'Age',               'Older (>= 45 years)', ...),\n",
       "            (              'Age',               'Older (>= 45 years)', ...),\n",
       "            (              'Age',               'Older (>= 45 years)', ...),\n",
       "            (              'Age',              'Younger (< 45 years)', ...),\n",
       "            (              'Age',              'Younger (< 45 years)', ...),\n",
       "            (              'Age',              'Younger (< 45 years)', ...),\n",
       "            (              'Age',              'Younger (< 45 years)', ...),\n",
       "            (              'Age',          'Sectoral Age Segregation', ...),\n",
       "            (  'Total Workforce',                   'Total Workforce', ...),\n",
       "            (  'Total Workforce',                   'Total Workforce', ...)],\n",
       "           names=['Variables', 'Categories', 'Counts'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sectors.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors.columns = [\n",
    "    '_'.join(col) \n",
    "    if 'SBI Sector Titles' not in col \n",
    "    and 'Total Workforce' not in col \n",
    "    else col[-1] \n",
    "    for col in df_sectors.columns\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors.rename(\n",
    "    columns={\n",
    "        'Keywords': 'Search Keyword', \n",
    "        'Code': 'Sector Code', \n",
    "        'Sector Name': 'Sector', \n",
    "        'Gender_Female_n': 'Female Count (x 1000)', \n",
    "        'Gender_Male_n': 'Male Count (x 1000)', \n",
    "        'Gender_Sectoral Gender Segregation_Dominant Category': 'Gender', \n",
    "        'Age_Sectoral Age Segregation_Dominant Category': 'Age', \n",
    "        'n': 'Sector Count (x 1000)', \n",
    "    },\n",
    "    inplace=True,\n",
    "    errors='ignore',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors = df_sectors.explode(\n",
    "    'Search Keyword', ignore_index=True\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before adding sector data, make sure keywords are correct as to not have any missing sector data when merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a manually collected dictionary of incorrect/faulty keywords in scraped site data\n",
    "with open(f'{scraped_data}CBS/Data/keyword_trans_dict.txt') as f:\n",
    "    keyword_trans_dict = json.load(f)\n",
    "\n",
    "def fix_keywords(df_temp):\n",
    "\n",
    "    if len(df_temp) > 0 and isinstance(df_temp, pd.DataFrame):\n",
    "        for key, value in keyword_trans_dict.items():\n",
    "            df_temp.loc[\n",
    "                df_temp[df_temp['Search Keyword'].notnull()]['Search Keyword'].astype(str).apply(\n",
    "                lambda x: x.lower().strip()\n",
    "                ) == str(key).lower().strip(), 'Search Keyword'\n",
    "            ] = str(value).lower().strip()\n",
    "\n",
    "        unfixed = df_temp.loc[\n",
    "            df_temp[df_temp['Search Keyword'].notnull()]['Search Keyword'].astype(str).apply(lambda x: x.lower().strip()).isin([x.lower().strip() for x in list(keyword_trans_dict.keys())])\n",
    "        ]\n",
    "\n",
    "        if len(unfixed) != 0:\n",
    "            for key, value in keyword_trans_dict.items():\n",
    "                for idx, row in df_temp.iterrows():\n",
    "                    if row['Search Keyword'].astype(str).lower().strip() == str(key).lower().strip():\n",
    "                        df_temp.loc[idx, 'Search Keyword'] = str(value).lower().strip()\n",
    "    \n",
    "        unfixed = df_temp.loc[\n",
    "                df_temp[df_temp['Search Keyword'].notnull()]['Search Keyword'].astype(str).apply(lambda x: x.lower().strip()).isin([x.lower().strip() for x in list(keyword_trans_dict.keys())])\n",
    "            ]\n",
    "        if len(unfixed) != 0:\n",
    "            print('Some keywords were not fixed. Please check file unfixed_keywords.txt in data directory.')\n",
    "            with open(f'{data_dir}unfixed_keywords.txt', 'w') as f:\n",
    "                json.dump(unfixed, f)\n",
    "    \n",
    "    return df_temp\n",
    "\n",
    "# Fix keywords\n",
    "if len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]) != 0:\n",
    "    print('Some search keywords did not match a sector. Fixing')\n",
    "#     print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
    "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n",
    "    df_jobs = fix_keywords(df_jobs)\n",
    "#     print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
    "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.merge(df_sectors, on='Search Keyword', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17599"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17599 entries, 0 to 17598\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Search Keyword                                  17599 non-null  object \n",
      " 1   Platform                                        17599 non-null  object \n",
      " 2   Job ID                                          17599 non-null  object \n",
      " 3   Job Title                                       17599 non-null  object \n",
      " 4   Company Name                                    17597 non-null  object \n",
      " 5   Location                                        17599 non-null  object \n",
      " 6   Job Description                                 17599 non-null  object \n",
      " 7   Rating                                          3780 non-null   float64\n",
      " 8   Employment Type                                 17017 non-null  object \n",
      " 9   Company URL                                     15959 non-null  object \n",
      " 10  Job URL                                         17599 non-null  object \n",
      " 11  Job Age                                         17599 non-null  object \n",
      " 12  Job Age Number                                  17599 non-null  object \n",
      " 13  Collection Date                                 17599 non-null  object \n",
      " 14  Data Row                                        13816 non-null  float64\n",
      " 15  Tracking ID                                     13816 non-null  object \n",
      " 16  Industry                                        14401 non-null  object \n",
      " 17  Job Date                                        13819 non-null  object \n",
      " 18  Type of ownership                               582 non-null    object \n",
      " 19  Language                                        17599 non-null  object \n",
      " 20  Dutch Requirement                               17599 non-null  object \n",
      " 21  English Requirement                             17599 non-null  object \n",
      " 22  Sector Code                                     17599 non-null  object \n",
      " 23  Sector                                          17599 non-null  object \n",
      " 24  Keywords Count                                  17599 non-null  float64\n",
      " 25  % per Sector                                    17599 non-null  float64\n",
      " 26  % per Social Category                           17599 non-null  float64\n",
      " 27  % per Workforce                                 17599 non-null  float64\n",
      " 28  Female Count (x 1000)                           17599 non-null  float64\n",
      " 29  Gender_Female_% per Sector                      17599 non-null  float64\n",
      " 30  Gender_Female_% per Social Category             17599 non-null  float64\n",
      " 31  Gender_Female_% per Workforce                   17599 non-null  float64\n",
      " 32  Male Count (x 1000)                             17599 non-null  float64\n",
      " 33  Gender_Male_% per Sector                        17599 non-null  float64\n",
      " 34  Gender_Male_% per Social Category               17599 non-null  float64\n",
      " 35  Gender_Male_% per Workforce                     17599 non-null  float64\n",
      " 36  Gender                                          17599 non-null  object \n",
      " 37  Age_Older (>= 45 years)_n                       17599 non-null  float64\n",
      " 38  Age_Older (>= 45 years)_% per Sector            17599 non-null  float64\n",
      " 39  Age_Older (>= 45 years)_% per Social Category   17599 non-null  float64\n",
      " 40  Age_Older (>= 45 years)_% per Workforce         17599 non-null  float64\n",
      " 41  Age_Younger (< 45 years)_n                      17599 non-null  float64\n",
      " 42  Age_Younger (< 45 years)_% per Sector           17599 non-null  float64\n",
      " 43  Age_Younger (< 45 years)_% per Social Category  17599 non-null  float64\n",
      " 44  Age_Younger (< 45 years)_% per Workforce        17599 non-null  float64\n",
      " 45  Age                                             17599 non-null  object \n",
      " 46  Sector Count (x 1000)                           17599 non-null  float64\n",
      " 47  % Sector per Workforce                          17599 non-null  float64\n",
      "dtypes: float64(24), object(24)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there is any missing sector data in the merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Sector'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_jobs['Sector'].isna().sum() != 0:\n",
    "    print('Some search keywords did not match a sector. Fixing')\n",
    "    print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
    "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n",
    "    df_jobs = fix_keywords(df_jobs)\n",
    "    print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
    "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mixed Gender    12256\n",
       "Male             3830\n",
       "Female           1513\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Gender'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mixed Age    11467\n",
       "Older         3778\n",
       "Younger       2354\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Age'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_jobs['Sector'].isna().sum() == 0:\n",
    "    if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "        df_jobs.to_pickle(f'{df_save_dir}/df_jobs_including_sector_data.pkl')\n",
    "\n",
    "        df_jobs.to_csv(f'{df_save_dir}/df_jobs_including_sector_data.csv', index=False)\n",
    "    else:\n",
    "        print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n",
    "else:\n",
    "    print(f\"MISSING SECTOR DATA: COUNT {df_jobs['Sector'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add categorical data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_JOBS_INCLUDING_SECTOR_DATA\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# df save sir\n",
    "df_save_dir = f'{data_dir}final dfs/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to order categories\n",
    "def categorize_df_gender_age(\n",
    "    df,\n",
    "    gender_order = ['Female', 'Mixed Gender', 'Male'],\n",
    "    age_order = ['Older', 'Mixed Age', 'Younger'],\n",
    "    ivs = ['Gender', 'Age']\n",
    "):\n",
    "    # Arrange Categories\n",
    "    for iv in ivs:\n",
    "        if iv == 'Gender':\n",
    "            order = gender_order\n",
    "        elif iv == 'Age':\n",
    "            order = age_order\n",
    "        try:\n",
    "            df[iv] = df[iv].astype('category').cat.reorder_categories(order, ordered=True)\n",
    "\n",
    "            df[iv] = pd.Categorical(\n",
    "                df[iv], categories=order, ordered=True\n",
    "            )\n",
    "            df[f'{iv}_Num'] = pd.to_numeric(df[iv].cat.codes).astype('int64')\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to print df gender and age info\n",
    "def df_gender_age_info(\n",
    "    df,\n",
    "    ivs_all = [\n",
    "        'Gender',\n",
    "        'Gender_Num',\n",
    "        'Gender_Female',\n",
    "        'Gender_Mixed',\n",
    "        'Gender_Male',\n",
    "        'Age',\n",
    "        'Age_Num',\n",
    "        'Age_Older',\n",
    "        'Age_Mixed',\n",
    "        'Age_Younger',\n",
    "    ],\n",
    "):\n",
    "    # Print Info\n",
    "    print('\\nDF INFO:\\n')\n",
    "    df.info()\n",
    "\n",
    "    for iv in ivs_all:\n",
    "        try:\n",
    "            print('='*20)\n",
    "            print(f'{iv}:')\n",
    "            print('-'*20)\n",
    "            print(f'{iv} Counts:\\n{df[f\"{iv}\"].value_counts()}')\n",
    "            print('-'*20)\n",
    "            print(f'{iv} Percentages:\\n{df[f\"{iv}\"].value_counts(normalize=True).mul(100).round(1).astype(float)}')\n",
    "            try:\n",
    "                print('-'*20)\n",
    "                print(f'{iv} Mean: {df[f\"{iv}\"].mean().round(2).astype(float)}')\n",
    "                print('-'*20)\n",
    "                print(f'{iv} Standard Deviation: {df[f\"{iv}\"].std().round(2).astype(float)}')\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception:\n",
    "            print(f'{iv} not available.')\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{df_save_dir}/df_jobs_including_sector_data.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17599 entries, 0 to 17598\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Search Keyword                                  17599 non-null  object \n",
      " 1   Platform                                        17599 non-null  object \n",
      " 2   Job ID                                          17599 non-null  object \n",
      " 3   Job Title                                       17599 non-null  object \n",
      " 4   Company Name                                    17597 non-null  object \n",
      " 5   Location                                        17599 non-null  object \n",
      " 6   Job Description                                 17599 non-null  object \n",
      " 7   Rating                                          3780 non-null   float64\n",
      " 8   Employment Type                                 17017 non-null  object \n",
      " 9   Company URL                                     15959 non-null  object \n",
      " 10  Job URL                                         17599 non-null  object \n",
      " 11  Job Age                                         17599 non-null  object \n",
      " 12  Job Age Number                                  17599 non-null  object \n",
      " 13  Collection Date                                 17599 non-null  object \n",
      " 14  Data Row                                        13816 non-null  float64\n",
      " 15  Tracking ID                                     13816 non-null  object \n",
      " 16  Industry                                        14401 non-null  object \n",
      " 17  Job Date                                        13819 non-null  object \n",
      " 18  Type of ownership                               582 non-null    object \n",
      " 19  Language                                        17599 non-null  object \n",
      " 20  Dutch Requirement                               17599 non-null  object \n",
      " 21  English Requirement                             17599 non-null  object \n",
      " 22  Sector Code                                     17599 non-null  object \n",
      " 23  Sector                                          17599 non-null  object \n",
      " 24  Keywords Count                                  17599 non-null  float64\n",
      " 25  % per Sector                                    17599 non-null  float64\n",
      " 26  % per Social Category                           17599 non-null  float64\n",
      " 27  % per Workforce                                 17599 non-null  float64\n",
      " 28  Female Count (x 1000)                           17599 non-null  float64\n",
      " 29  Gender_Female_% per Sector                      17599 non-null  float64\n",
      " 30  Gender_Female_% per Social Category             17599 non-null  float64\n",
      " 31  Gender_Female_% per Workforce                   17599 non-null  float64\n",
      " 32  Male Count (x 1000)                             17599 non-null  float64\n",
      " 33  Gender_Male_% per Sector                        17599 non-null  float64\n",
      " 34  Gender_Male_% per Social Category               17599 non-null  float64\n",
      " 35  Gender_Male_% per Workforce                     17599 non-null  float64\n",
      " 36  Gender                                          17599 non-null  object \n",
      " 37  Age_Older (>= 45 years)_n                       17599 non-null  float64\n",
      " 38  Age_Older (>= 45 years)_% per Sector            17599 non-null  float64\n",
      " 39  Age_Older (>= 45 years)_% per Social Category   17599 non-null  float64\n",
      " 40  Age_Older (>= 45 years)_% per Workforce         17599 non-null  float64\n",
      " 41  Age_Younger (< 45 years)_n                      17599 non-null  float64\n",
      " 42  Age_Younger (< 45 years)_% per Sector           17599 non-null  float64\n",
      " 43  Age_Younger (< 45 years)_% per Social Category  17599 non-null  float64\n",
      " 44  Age_Younger (< 45 years)_% per Workforce        17599 non-null  float64\n",
      " 45  Age                                             17599 non-null  object \n",
      " 46  Sector Count (x 1000)                           17599 non-null  float64\n",
      " 47  % Sector per Workforce                          17599 non-null  float64\n",
      "dtypes: float64(24), object(24)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.join(pd.get_dummies(df_jobs[['Gender', 'Age']], dtype='int64'))\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mixed Gender    12256\n",
       "Male             3830\n",
       "Female           1513\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12256\n",
       "2     3830\n",
       "0     1513\n",
       "Name: Gender_Num, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Gender_Num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16086\n",
       "1     1513\n",
       "Name: Gender_Female, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Gender_Female'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_including_sector_genage_data.pkl')\n",
    "\n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_including_sector_genage_data.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use spacy to split job ads to sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_JOBS_INCLUDING_SECTOR_GENAGE_DATA\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# df save sir\n",
    "df_save_dir = f'{data_dir}final dfs/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "languages = [\"en\", \"['nl', 'en']\", ['en', 'nl']]\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "random.seed(42)\n",
    "\n",
    "# Set up Spacy\n",
    "import spacy\n",
    "from spacy.symbols import NORM, ORTH, LEMMA, POS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Set up NLK\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "from nltk.tag import pos_tag, pos_tag_sents\n",
    "\n",
    "nltk_path = f'{llm_path}/nltk'\n",
    "nltk.data.path.append(nltk_path)\n",
    "\n",
    "nltk.download('words', download_dir = nltk_path)\n",
    "nltk.download('stopwords', download_dir = nltk_path)\n",
    "nltk.download('punkt', download_dir = nltk_path)\n",
    "nltk.download('averaged_perceptron_tagger', download_dir = nltk_path)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Set up Gensim\n",
    "from gensim.utils import save_as_line_sentence, simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string, preprocess_documents\n",
    "\n",
    "# Set up Bert\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline,\n",
    "    BertTokenizer, BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments,\n",
    "    DistilBertTokenizerFast, DistilBertForSequenceClassification, BertForPreTraining, BertConfig, BertModel\n",
    ")\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained(bert_model_name, strip_accents = True)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{df_save_dir}/df_jobs_including_sector_genage_data.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17599 entries, 0 to 17598\n",
      "Data columns (total 56 columns):\n",
      " #   Column                                          Non-Null Count  Dtype   \n",
      "---  ------                                          --------------  -----   \n",
      " 0   Search Keyword                                  17599 non-null  object  \n",
      " 1   Platform                                        17599 non-null  object  \n",
      " 2   Job ID                                          17599 non-null  object  \n",
      " 3   Job Title                                       17599 non-null  object  \n",
      " 4   Company Name                                    17597 non-null  object  \n",
      " 5   Location                                        17599 non-null  object  \n",
      " 6   Job Description                                 17599 non-null  object  \n",
      " 7   Rating                                          3780 non-null   float64 \n",
      " 8   Employment Type                                 17017 non-null  object  \n",
      " 9   Company URL                                     15959 non-null  object  \n",
      " 10  Job URL                                         17599 non-null  object  \n",
      " 11  Job Age                                         17599 non-null  object  \n",
      " 12  Job Age Number                                  17599 non-null  object  \n",
      " 13  Collection Date                                 17599 non-null  object  \n",
      " 14  Data Row                                        13816 non-null  float64 \n",
      " 15  Tracking ID                                     13816 non-null  object  \n",
      " 16  Industry                                        14401 non-null  object  \n",
      " 17  Job Date                                        13819 non-null  object  \n",
      " 18  Type of ownership                               582 non-null    object  \n",
      " 19  Language                                        17599 non-null  object  \n",
      " 20  Dutch Requirement                               17599 non-null  object  \n",
      " 21  English Requirement                             17599 non-null  object  \n",
      " 22  Sector Code                                     17599 non-null  object  \n",
      " 23  Sector                                          17599 non-null  object  \n",
      " 24  Keywords Count                                  17599 non-null  float64 \n",
      " 25  % per Sector                                    17599 non-null  float64 \n",
      " 26  % per Social Category                           17599 non-null  float64 \n",
      " 27  % per Workforce                                 17599 non-null  float64 \n",
      " 28  Female Count (x 1000)                           17599 non-null  float64 \n",
      " 29  Gender_Female_% per Sector                      17599 non-null  float64 \n",
      " 30  Gender_Female_% per Social Category             17599 non-null  float64 \n",
      " 31  Gender_Female_% per Workforce                   17599 non-null  float64 \n",
      " 32  Male Count (x 1000)                             17599 non-null  float64 \n",
      " 33  Gender_Male_% per Sector                        17599 non-null  float64 \n",
      " 34  Gender_Male_% per Social Category               17599 non-null  float64 \n",
      " 35  Gender_Male_% per Workforce                     17599 non-null  float64 \n",
      " 36  Gender                                          17599 non-null  category\n",
      " 37  Age_Older (>= 45 years)_n                       17599 non-null  float64 \n",
      " 38  Age_Older (>= 45 years)_% per Sector            17599 non-null  float64 \n",
      " 39  Age_Older (>= 45 years)_% per Social Category   17599 non-null  float64 \n",
      " 40  Age_Older (>= 45 years)_% per Workforce         17599 non-null  float64 \n",
      " 41  Age_Younger (< 45 years)_n                      17599 non-null  float64 \n",
      " 42  Age_Younger (< 45 years)_% per Sector           17599 non-null  float64 \n",
      " 43  Age_Younger (< 45 years)_% per Social Category  17599 non-null  float64 \n",
      " 44  Age_Younger (< 45 years)_% per Workforce        17599 non-null  float64 \n",
      " 45  Age                                             17599 non-null  category\n",
      " 46  Sector Count (x 1000)                           17599 non-null  float64 \n",
      " 47  % Sector per Workforce                          17599 non-null  float64 \n",
      " 48  Gender_Female                                   17599 non-null  int64   \n",
      " 49  Gender_Male                                     17599 non-null  int64   \n",
      " 50  Gender_Mixed Gender                             17599 non-null  int64   \n",
      " 51  Age_Mixed Age                                   17599 non-null  int64   \n",
      " 52  Age_Older                                       17599 non-null  int64   \n",
      " 53  Age_Younger                                     17599 non-null  int64   \n",
      " 54  Gender_Num                                      17599 non-null  int64   \n",
      " 55  Age_Num                                         17599 non-null  int64   \n",
      "dtypes: category(2), float64(24), int64(8), object(22)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a list of punctuations that determine sentence boundry, i.e., split characters\n",
    "def make_custom_punct_chars(main_punct_chars = [':', '|'], repeated_punct_chars = ['\\n', ',']):\n",
    "    custom_punct_chars = []\n",
    "    temp_multi = []\n",
    "    temp_spaced = []\n",
    "\n",
    "    for punct_char in main_punct_chars:\n",
    "        custom_punct_chars+= f'{punct_char}', f'{punct_char} '\n",
    "\n",
    "    for idx in range(4):\n",
    "        for punct_char in repeated_punct_chars:\n",
    "            temp_multi.append(f'{punct_char}'*int(idx+1))\n",
    "            temp_spaced.append(f'{punct_char} '*int(idx+1))\n",
    "\n",
    "    for multi, spaced in zip(temp_multi, temp_spaced):\n",
    "        custom_punct_chars+= multi, spaced\n",
    "\n",
    "    custom_punct_chars.remove(',')\n",
    "    custom_punct_chars.remove(', ')\n",
    "\n",
    "    return custom_punct_chars\n",
    "\n",
    "custom_punct_chars = make_custom_punct_chars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " ': ',\n",
       " '|',\n",
       " '| ',\n",
       " '\\n',\n",
       " '\\n ',\n",
       " '\\n\\n',\n",
       " '\\n \\n ',\n",
       " ',,',\n",
       " ', , ',\n",
       " '\\n\\n\\n',\n",
       " '\\n \\n \\n ',\n",
       " ',,,',\n",
       " ', , , ',\n",
       " '\\n\\n\\n\\n',\n",
       " '\\n \\n \\n \\n ',\n",
       " ',,,,',\n",
       " ', , , , ']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_punct_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 ms, sys: 3.94 ms, total: 9.86 ms\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add sentencizer to spacy pipe and set custom punctuations\n",
    "if 'sentencizer' not in nlp.pipe_names:\n",
    "    sentencizer = nlp.add_pipe('sentencizer')\n",
    "sentencizer.punct_chars.update(custom_punct_chars)\n",
    "\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
    "        pickle.dump(sentencizer.punct_chars, f)\n",
    "\n",
    "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
    "    custom_punct_chars = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special cases to spacy\n",
    "special_cases_dict = {\n",
    "    'incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'incl. ': [{65: 'incl', 67: 'including'}],\n",
    "    '(incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'etc.': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'etc. ': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'e.g.': [{65: 'e.g', 67: 'for example'}],\n",
    "    'e.g. ': [{65: 'e.g', 67: 'for example'}],\n",
    "}\n",
    "\n",
    "nlp.tokenizer.rules.update(special_cases_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 6s, sys: 32.1 s, total: 19min 38s\n",
      "Wall time: 23min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Spacy sentencize\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    df_jobs['Job Description spacy_sentencized'] = df_jobs['Job Description'].apply(\n",
    "        lambda job_description: [\n",
    "            sent \n",
    "            for sentence in nlp(job_description).sents \n",
    "            for sent in re.split(pattern, sentence.text) \n",
    "            if len(sent) != 0 \n",
    "        ]\n",
    "    )\n",
    "\n",
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_sentencized.pkl')\n",
    "\n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_sentencized.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [About Our Client, The Global KYC organisation...\n",
       "1    [Your role:, Were in business to save our hom...\n",
       "2    [During the past four years Colourful Rebel ha...\n",
       "3    [Job Description, We are currently recruiting ...\n",
       "4    [KARL LAGERFELD COMPANY PROFILE, The house of ...\n",
       "Name: Job Description spacy_sentencized, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Job Description spacy_sentencized'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{df_save_dir}/df_jobs_sentencized.pkl')\n",
    "\n",
    "    df_jobs.to_csv(f'{df_save_dir}/df_jobs_sentencized.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
