{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
                "    for _ in range(5):\n",
                "\n",
                "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "            code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "            if code_dir is not None:\n",
                "                break\n",
                "else:\n",
                "    code_dir = str(Path.cwd())\n",
                "sys.path.append(code_dir)\n",
                "\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bc94e31adc11437a912ed79301855679",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 640x480 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.forestIV import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3936e59",
            "metadata": {},
            "source": [
                "### Set variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "3b9d1a7b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                }
            ],
            "source": [
                "# Variables\n",
                "method = 'Supervised'\n",
                "classifiers_type = 'all'\n",
                "if classifiers_type == 'nonlinear':\n",
                "    classifiers_pipe = classifiers_pipe_nonlinear\n",
                "elif classifiers_type == 'linear':\n",
                "    classifiers_pipe = classifiers_pipe_linear\n",
                "elif classifiers_type == 'ensemble':\n",
                "    classifiers_pipe = classifiers_pipe_ensemble\n",
                "elif classifiers_type == 'all':\n",
                "    classifiers_pipe = classifiers_pipe\n",
                "\n",
                "results_save_path = f'{models_save_path}{method} Results/'\n",
                "with open(f'{data_dir}{method}_results_save_path.txt', 'w') as f:\n",
                "    f.write(results_save_path)\n",
                "if not os.path.exists(results_save_path):\n",
                "    os.makedirs(results_save_path)\n",
                "done_xy_save_path = f'{results_save_path}Search+Xy/'\n",
                "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'w') as f:\n",
                "    f.write(done_xy_save_path)\n",
                "if not os.path.exists(done_xy_save_path):\n",
                "    os.makedirs(done_xy_save_path)\n",
                "\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score, zero_division=0),\n",
                "    'recall_score': make_scorer(recall_score, zero_division=0),\n",
                "    'accuracy_score': make_scorer(accuracy_score, zero_division=0),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    # f'{scoring.title()} Best Score': np.nan,\n",
                "    # f'{scoring.title()} Best Threshold': np.nan,\n",
                "    # 'Train - Mean Cross Validation Score': np.nan,\n",
                "    # f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    # f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    # 'Test - Mean Cross Validation Score': np.nan,\n",
                "    # f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    # f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Average Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Brier Score': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'R2 Score': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan,\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "cores = multiprocessing.cpu_count()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prob_confirmatory_tests(y_pred, y_pred_prob):\n",
                "\n",
                "    # Confirmatory Regression\n",
                "    print('+'*20)\n",
                "    print('Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob')\n",
                "    print('-'*20)\n",
                "    print('T-Test y_pred_prob ~ y_pred:')\n",
                "    levene = scipy.stats.levene(y_pred_prob, y_pred)\n",
                "    equal_var_levene = levene.pvalue < 0.05\n",
                "    print(scipy.stats.ttest_ind(y_pred_prob, y_pred, equal_var=equal_var_levene))\n",
                "\n",
                "    print('\\n')\n",
                "    print('-'*20)\n",
                "    print('Logit y_pred ~ y_pred_prob:')\n",
                "    try:\n",
                "        logit_model = sm.Logit(endog=y_pred, exog=y_pred_prob)\n",
                "        logit_results = logit_model.fit()\n",
                "        std_coef = logit_results.params[0] / np.std(y_pred_prob)\n",
                "        std_err = logit_results.bse[0]\n",
                "        log_likelihood = logit_results.llf\n",
                "        print(logit_results.summary())\n",
                "        print('-'*20)\n",
                "        print(f'Std Coef: {std_coef}')\n",
                "        print(f'Std Err: {std_err}')\n",
                "        print(f'Log Likelihood: {log_likelihood}')\n",
                "    except Exception as e:\n",
                "        print(type(e).__name__)\n",
                "\n",
                "    print('-'*20)\n",
                "    print('\\n')\n",
                "    print('-'*20)\n",
                "    print('OLS y_pred_prob ~ y_pred:')\n",
                "    try:\n",
                "        ols_model = sm.OLS(endog=y_pred_prob, exog=y_pred)\n",
                "        ols_results = ols_model.fit()\n",
                "        std_coef = ols_results.params[0] / np.std(y_pred)\n",
                "        std_err = ols_results.bse[0]\n",
                "        print(ols_results.summary())\n",
                "        print('-'*20)\n",
                "        print(f'Std Coef: {std_coef}')\n",
                "        print(f'Std Err: {std_err}')\n",
                "    except Exception as e:\n",
                "        print(type(e).__name__)\n",
                "\n",
                "    print('-'*20)\n",
                "    print('+'*20)\n",
                "    print('\\n')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "f15e44f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_df_full_summary_excel(\n",
                "    df_full_summary,\n",
                "    title,\n",
                "    text_to_add_list,\n",
                "    file_save_path,\n",
                "    sheet_name=None,\n",
                "    startrow=None,\n",
                "    startcol=None,\n",
                "):\n",
                "    if sheet_name is None:\n",
                "        sheet_name = 'All'\n",
                "    if startrow is None:\n",
                "        startrow = 1\n",
                "    if startcol is None:\n",
                "        startcol = 1\n",
                "\n",
                "    # Define last rows and cols locs\n",
                "    header_range = 1\n",
                "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
                "    endcol = startcol + df_full_summary.shape[1]\n",
                "\n",
                "    # Remove NAs\n",
                "    df_full_summary = df_full_summary.fillna('')\n",
                "\n",
                "    # Write\n",
                "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
                "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
                "    workbook  = writer.book\n",
                "    worksheet = writer.sheets[sheet_name]\n",
                "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
                "\n",
                "    # Title\n",
                "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
                "\n",
                "    # Main body\n",
                "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
                "\n",
                "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
                "        row_to_write = startrow + header_range + r\n",
                "        col_to_write = startcol + 1 + c # 1 is for index\n",
                "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
                "\n",
                "        if r == 0:\n",
                "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
                "\n",
                "        if r == body_max_row_idx-1:\n",
                "            body_formats |= {'bottom': True}\n",
                "\n",
                "        if c == 0:\n",
                "            body_formats |= {'align': 'left'}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
                "\n",
                "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
                "\n",
                "    # Add Note\n",
                "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
                "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
                "    # Add text\n",
                "    for i, text in enumerate(text_to_add_list):\n",
                "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
                "\n",
                "    writer.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "96e6d325",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_full_report(\n",
                "    results, dv, analysis_type, model_name, dvs_name, ivs_name, ivs_type, df_name,\n",
                "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
                "):\n",
                "    '''\n",
                "    Make a full report for a regression analysis.\n",
                "    results: statsmodels regression results object or list of results objects\n",
                "    dv: str, dependent variable name\n",
                "    '''\n",
                "\n",
                "    if regression_info_dict is None:\n",
                "        # Regression info dict\n",
                "        regression_info_dict = {\n",
                "            'F': lambda x: f'{x.fvalue:.2f}',\n",
                "            'F (p-value)': lambda x: f'{x.f_pvalue:.2f}',\n",
                "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
                "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
                "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
                "            'R-squared': lambda x: f'{x.rsquared:.2f}',\n",
                "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.2f}',\n",
                "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.2f}',\n",
                "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.2f}',\n",
                "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.2f}',\n",
                "            't': lambda x: f'{x.tvalues[0]:.2f}',\n",
                "            't (p-value)': lambda x: f'{x.pvalues[0]:.2f}',\n",
                "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.2f} - {x.conf_int().iloc[0, 1]:.2f}',\n",
                "            'Log-Likelihood': lambda x: f'{x.llf:.2f}',\n",
                "            'Pseudo R2': lambda x: f'{x.prsquared:.2f}',\n",
                "            'AIC': lambda x: f'{x.aic:.2f}',\n",
                "            'BIC': lambda x: f'{x.bic:.2f}',\n",
                "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.2f}',\n",
                "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.2f}',\n",
                "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.2f}',\n",
                "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.2f}',\n",
                "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.2f}',\n",
                "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.2f}',\n",
                "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.2f}',\n",
                "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.2f}',\n",
                "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.2f}',\n",
                "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
                "            'N': lambda x: f'{int(x.nobs):d}',\n",
                "            # 'Summary': lambda x: f'{x.summary()}',\n",
                "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.2f}',\n",
                "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.2f}',\n",
                "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.2f}',\n",
                "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.2f}',\n",
                "        }\n",
                "        if isinstance(results, list):\n",
                "            results_to_check = results[0]\n",
                "        else:\n",
                "            results_to_check = results\n",
                "        if all('const' in x for x in zip(results_to_check.params.index, results_to_check.bse.index, results_to_check.tvalues.index, results_to_check.pvalues.index)):\n",
                "            regression_info_dict = regression_info_dict | {\n",
                "                'Intercept': lambda x: f'{x.params[\"const\"]:.5f}',\n",
                "                'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.5f}',\n",
                "                'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.5f}',\n",
                "                'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.5f}',\n",
                "                'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.5f} - {x.conf_int().loc[\"const\"][1]:.5f}',\n",
                "            }\n",
                "    if model_names is None:\n",
                "        if isinstance(results, list):\n",
                "            model_names = [\n",
                "                f'{results_to_check.model.endog_names.split(\"_\")[0] if \"_\" in results_to_check.model.endog_names else results_to_check.model.endog_names} Model {i}'\n",
                "                for i in range(len(results))\n",
                "            ]\n",
                "            model_names[0] = model_names[0].replace('Model 0', 'Full Model')\n",
                "        else:\n",
                "            model_names = [\n",
                "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
                "            ]\n",
                "\n",
                "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
                "    if text_to_add_list is None:\n",
                "        text_to_add_list = []\n",
                "        if regressor_order is not None:\n",
                "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
                "\n",
                "        else:\n",
                "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
                "\n",
                "    if title is None:\n",
                "        title = f'{model_name} {analysis_type}: {dvs_name} x {ivs_name}'\n",
                "\n",
                "    try:\n",
                "        # Statsmodels summary_col\n",
                "        full_summary = summary_col(\n",
                "            results,\n",
                "            stars=True,\n",
                "            info_dict=regression_info_dict,\n",
                "            regressor_order=regressor_order,\n",
                "            float_format='%0.2f',\n",
                "            model_names=model_names,\n",
                "        )\n",
                "        if isinstance(results, list) and len(results) > 4:\n",
                "            full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
                "\n",
                "        # Add title and notes\n",
                "        full_summary.add_title(title)\n",
                "        text_to_add_list.extend(full_summary.extra_txt)\n",
                "        for text in text_to_add_list:\n",
                "            full_summary.add_text(text)\n",
                "        # Save\n",
                "        save_name = f'{table_save_path}{model_name} {df_name} - ALL {dv} {order_type} {analysis_type} on {ivs_type}'\n",
                "        df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
                "        df_full_summary.to_csv(f'{save_name}.csv')\n",
                "        df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "        save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
                "\n",
                "        return full_summary\n",
                "    except IndexError as e:\n",
                "        print(f'Making full report for {model_names[0]} due to the following error: {e}')\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "bbe40924",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to compare and produce Unbiased and Biased OLS Models\n",
                "def compare_actual_and_predicted(df, analysis_type, iv_names=None, print_enabled=None):\n",
                "    if print_enabled is None:\n",
                "        print_enabled = True\n",
                "    dv_names_dict = defaultdict(lambda: defaultdict())\n",
                "\n",
                "    for dv in tqdm.tqdm(dvs):\n",
                "        if analysis_type == 'pre_classification':\n",
                "            if iv_names is None:\n",
                "                iv_names = ivs_dummy_perc_and_perc_interactions# + controls[:1]\n",
                "            dv_names_dict[dv] = {\n",
                "                'Unbiased': {'dv_names': f'{dv}_actual'},\n",
                "                'Biased': {'dv_names': f'{dv}_predicted'}\n",
                "            }\n",
                "            df = df.loc[\n",
                "                (~df[dv_names_dict[dv]['Unbiased']['dv_names']].isna())\n",
                "                & (~df[dv_names_dict[dv]['Biased']['dv_names']].isna())\n",
                "            ]\n",
                "            print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        elif analysis_type == 'post_classification':\n",
                "            if iv_names is None:\n",
                "                iv_names = ivs_dummy_perc_and_perc_interactions[0]\n",
                "            if f'{dv}_aggr_unlabeled_predicted' in df.columns:\n",
                "                dv_names_dict[dv] = {\n",
                "                    'Biased': {'dv_names': f'{dv}_aggr_unlabeled_predicted'},\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[dv_names_dict[dv]['Biased']['dv_names']].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "            elif f'{dv}_actual' in df.columns:\n",
                "                dv_names_dict[dv] = {\n",
                "                    'Unbiased': {'dv_names': f'{dv}_actual'},\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[dv_names_dict[dv]['Unbiased']['dv_names']].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        print(f'Analyzing {dv} {dv_names_dict[dv].keys()} Models')\n",
                "\n",
                "        for dv_type, dv_names in tqdm.tqdm(dv_names_dict[dv].items()):\n",
                "            if analysis_type == 'pre_classification':\n",
                "                endog = df[dv_names['dv_names']]\n",
                "                exog = df[iv_names]\n",
                "            elif analysis_type == 'post_classification':\n",
                "                endog = df[iv_names]\n",
                "                exog = df[dv_names['dv_names']]\n",
                "\n",
                "            model = sm.OLS(endog=endog, exog=exog, data=df)\n",
                "            results = model.fit()\n",
                "            tt, df_std_coef = get_standardized_coefficients(results)\n",
                "            title = f'{analysis_type} {dv_type} OLS Regression {dv_names[\"dv_names\"]} x {iv_names[:3]} etc.'\n",
                "            full_summary = make_full_report(\n",
                "                results=results, dv=dv, analysis_type=dv_names['dv_names'], model_name=analysis_type, df_name=dv_type,\n",
                "                dvs_name=dv_names['dv_names'], ivs_name=iv_names[:3], ivs_type=iv_names[:3], title=title\n",
                "            )\n",
                "\n",
                "            dv_names_dict[dv][dv_type]['R-squared'] = results.rsquared\n",
                "            dv_names_dict[dv][dv_type]['Results'] = results\n",
                "\n",
                "            if print_enabled:\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "                print(f'{dv_type.upper()} {dv}\\n')\n",
                "                print('-'*20)\n",
                "                print('\\n')\n",
                "                print(f'{dv_type.upper()} SUMMARY RESULTS:')\n",
                "                print(results.summary())\n",
                "                print(full_summary)\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "                print(f'{dv_type.upper()} STANDARDIZED BETA REGRESSION COEFFICIENTS FOR {dv}:\\n{df_std_coef}')\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "\n",
                "            df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
                "            save_name = f'{table_save_path}{title}'\n",
                "            df_summary_results.to_csv(f'{save_name}.csv')\n",
                "            df_summary_results.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "            df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
                "            df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)\n",
                "\n",
                "        if dv_names_dict[dv][list(dv_names_dict[dv])[0]]['R-squared'] != dv_names_dict[dv][list(dv_names_dict[dv])[-1]]['R-squared']:\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[0]} R-Squared does not equal {list(dv_names_dict[dv])[-1]} R-Squared:')\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[0]} = {dv_names_dict[dv][list(dv_names_dict[dv])[0]][\"R-squared\"]:.3f}')\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[-1]} = {dv_names_dict[dv][list(dv_names_dict[dv])[-1]][\"R-squared\"]:.3f}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "    return dict(dv_names_dict)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fd32c435",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "923fee85",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataframe df_jobs_for_analysis loaded with shape: (308583, 101)\n"
                    ]
                }
            ],
            "source": [
                "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
                "    df_jobs_len = int(f.read())\n",
                "\n",
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
                "print(f'Dataframe df_jobs_for_analysis loaded with shape: {df_jobs.shape}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "aee1fd3d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_jobs['Warmth'].equals(df_jobs['Warmth_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "a183fc9d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_jobs['Competence'].equals(df_jobs['Competence_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "++++++++++++++++++++\n",
                        "Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob\n",
                        "--------------------\n",
                        "T-Test y_pred_prob ~ y_pred:\n",
                        "TtestResult(statistic=2.413999633045925, pvalue=0.015796033378415914, df=10166.0)\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Logit y_pred ~ y_pred_prob:\n",
                        "Optimization terminated successfully.\n",
                        "         Current function value: 0.641450\n",
                        "         Iterations 5\n",
                        "                           Logit Regression Results                           \n",
                        "==============================================================================\n",
                        "Dep. Variable:       Warmth_predicted   No. Observations:                 5084\n",
                        "Model:                          Logit   Df Residuals:                     5083\n",
                        "Method:                           MLE   Df Model:                            0\n",
                        "Date:                Fri, 17 Nov 2023   Pseudo R-squ.:                -0.08992\n",
                        "Time:                        09:32:11   Log-Likelihood:                -3261.1\n",
                        "converged:                       True   LL-Null:                       -2992.1\n",
                        "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
                        "==============================================================================\n",
                        "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------\n",
                        "Warmth         1.3015      0.063     20.739      0.000       1.179       1.425\n",
                        "==============================================================================\n",
                        "--------------------\n",
                        "Std Coef: 2.8483586228270865\n",
                        "Std Err: 0.06275695352189209\n",
                        "Log Likelihood: -3261.1304905301954\n",
                        "--------------------\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "OLS y_pred_prob ~ y_pred:\n",
                        "                                 OLS Regression Results                                \n",
                        "=======================================================================================\n",
                        "Dep. Variable:                 Warmth   R-squared (uncentered):                   0.666\n",
                        "Model:                            OLS   Adj. R-squared (uncentered):              0.666\n",
                        "Method:                 Least Squares   F-statistic:                          1.016e+04\n",
                        "Date:                Fri, 17 Nov 2023   Prob (F-statistic):                        0.00\n",
                        "Time:                        09:32:11   Log-Likelihood:                         -1336.6\n",
                        "No. Observations:                5084   AIC:                                      2675.\n",
                        "Df Residuals:                    5083   BIC:                                      2682.\n",
                        "Df Model:                           1                                                  \n",
                        "Covariance Type:            nonrobust                                                  \n",
                        "====================================================================================\n",
                        "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------------\n",
                        "Warmth_predicted     0.8479      0.008    100.787      0.000       0.831       0.864\n",
                        "==============================================================================\n",
                        "Omnibus:                      956.701   Durbin-Watson:                   1.691\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7095.272\n",
                        "Skew:                           0.698   Prob(JB):                         0.00\n",
                        "Kurtosis:                       8.616   Cond. No.                         1.00\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
                        "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                        "--------------------\n",
                        "Std Coef: 1.898035786441547\n",
                        "Std Err: 0.008412324482707005\n",
                        "--------------------\n",
                        "++++++++++++++++++++\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "prob_confirmatory_tests(\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Warmth_predicted'],\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Warmth'],\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "++++++++++++++++++++\n",
                        "Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob\n",
                        "--------------------\n",
                        "T-Test y_pred_prob ~ y_pred:\n",
                        "TtestResult(statistic=-0.8331732293355767, pvalue=0.4047666122342374, df=10165.99869941767)\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Logit y_pred ~ y_pred_prob:\n",
                        "Optimization terminated successfully.\n",
                        "         Current function value: 0.485062\n",
                        "         Iterations 6\n",
                        "                            Logit Regression Results                            \n",
                        "================================================================================\n",
                        "Dep. Variable:     Competence_predicted   No. Observations:                 5084\n",
                        "Model:                            Logit   Df Residuals:                     5083\n",
                        "Method:                             MLE   Df Model:                            0\n",
                        "Date:                  Fri, 17 Nov 2023   Pseudo R-squ.:                  0.2998\n",
                        "Time:                          09:32:11   Log-Likelihood:                -2466.1\n",
                        "converged:                         True   LL-Null:                       -3521.7\n",
                        "Covariance Type:              nonrobust   LLR p-value:                       nan\n",
                        "==============================================================================\n",
                        "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------\n",
                        "Competence     2.4218      0.072     33.635      0.000       2.281       2.563\n",
                        "==============================================================================\n",
                        "--------------------\n",
                        "Std Coef: 4.844130350891976\n",
                        "Std Err: 0.07200388205307288\n",
                        "Log Likelihood: -2466.056738705634\n",
                        "--------------------\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "OLS y_pred_prob ~ y_pred:\n",
                        "                                 OLS Regression Results                                \n",
                        "=======================================================================================\n",
                        "Dep. Variable:             Competence   R-squared (uncentered):                   0.830\n",
                        "Model:                            OLS   Adj. R-squared (uncentered):              0.830\n",
                        "Method:                 Least Squares   F-statistic:                          2.483e+04\n",
                        "Date:                Fri, 17 Nov 2023   Prob (F-statistic):                        0.00\n",
                        "Time:                        09:32:11   Log-Likelihood:                         -980.34\n",
                        "No. Observations:                5084   AIC:                                      1963.\n",
                        "Df Residuals:                    5083   BIC:                                      1969.\n",
                        "Df Model:                           1                                                  \n",
                        "Covariance Type:            nonrobust                                                  \n",
                        "========================================================================================\n",
                        "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "----------------------------------------------------------------------------------------\n",
                        "Competence_predicted     0.9037      0.006    157.572      0.000       0.892       0.915\n",
                        "==============================================================================\n",
                        "Omnibus:                      788.729   Durbin-Watson:                   1.760\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11800.090\n",
                        "Skew:                          -0.220   Prob(JB):                         0.00\n",
                        "Kurtosis:                      10.451   Cond. No.                         1.00\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
                        "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                        "--------------------\n",
                        "Std Coef: 1.8082950052507507\n",
                        "Std Err: 0.005735415498082976\n",
                        "--------------------\n",
                        "++++++++++++++++++++\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "prob_confirmatory_tests(\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Competence_predicted'],\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Competence'],\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ebecb79",
            "metadata": {},
            "source": [
                "## Check biased and unbiased regressions models using human annotated and classifier predicted Warmth and Competence\n",
                "Source: https://mochenyang.github.io/mochenyangblog/research/2022/01/10/ForestIV.html"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5499a77b",
            "metadata": {},
            "source": [
                "### Unbiased and Biased Warmth and CompetenceOLS regression with human annotated actual values as DV and all IVs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "08d54a15",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing dataframe of length 5084\n",
                        "Analyzing Warmth dict_keys(['Unbiased', 'Biased']) Models\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7887fb8fb13544c68b994dd662abdc5b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/118 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "711cfee4c11343038af0e0e6b63dfd57",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/118 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 2/2 [00:00<00:00,  4.45it/s]\n",
                        " 50%|█████     | 1/2 [00:00<00:00,  2.16it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Warmth Unbiased R-Squared does not equal Biased R-Squared:\n",
                        "Warmth Unbiased = 0.007\n",
                        "Warmth Biased = 0.006\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Processing dataframe of length 5084\n",
                        "Analyzing Competence dict_keys(['Unbiased', 'Biased']) Models\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "21736aace96d4994af07e52d5e3469f7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/118 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "821932f82feb4885824f7b275af410f9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/118 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 2/2 [00:00<00:00,  9.72it/s]\n",
                        "100%|██████████| 2/2 [00:00<00:00,  2.93it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Competence Unbiased R-Squared does not equal Biased R-Squared:\n",
                        "Competence Unbiased = 0.011\n",
                        "Competence Biased = 0.008\n",
                        "\n",
                        "\n",
                        "--------------------\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "dv_names_dict_pre_classification = compare_actual_and_predicted(df_jobs, analysis_type='pre_classification', print_enabled=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "33e3488f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'Warmth': {'Unbiased': {'dv_names': 'Warmth_actual',\n",
                            "   'R-squared': 0.006944728866440597,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x2a2509810>},\n",
                            "  'Biased': {'dv_names': 'Warmth_predicted',\n",
                            "   'R-squared': 0.00646988060605358,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x2e4d7af80>}},\n",
                            " 'Competence': {'Unbiased': {'dv_names': 'Competence_actual',\n",
                            "   'R-squared': 0.01120094874210642,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x2e4d1ded0>},\n",
                            "  'Biased': {'dv_names': 'Competence_predicted',\n",
                            "   'R-squared': 0.007661656638638381,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x2a33bd780>}}}"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>      <td>Warmth_actual</td>  <th>  R-squared:         </th> <td>   0.007</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.955</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>             <td>Fri, 17 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>0.000408</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                 <td>09:32:12</td>     <th>  Log-Likelihood:    </th> <td> -3214.4</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>      <td>  5084</td>      <th>  AIC:               </th> <td>   6455.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>          <td>  5071</td>      <th>  BIC:               </th> <td>   6540.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                     <td></td>                        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                           <td>-2530.2500</td> <td> 2.04e+04</td> <td>   -0.124</td> <td> 0.901</td> <td>-4.25e+04</td> <td> 3.74e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                            <td>-2530.3945</td> <td> 2.04e+04</td> <td>   -0.124</td> <td> 0.901</td> <td>-4.25e+04</td> <td> 3.74e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                             <td>-2530.4341</td> <td> 2.04e+04</td> <td>   -0.124</td> <td> 0.901</td> <td>-4.25e+04</td> <td> 3.74e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>              <td>   50.6766</td> <td>  407.346</td> <td>    0.124</td> <td> 0.901</td> <td> -747.898</td> <td>  849.251</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                <td>   50.5947</td> <td>  407.339</td> <td>    0.124</td> <td> 0.901</td> <td> -747.965</td> <td>  849.155</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                               <td>-2530.3020</td> <td> 2.04e+04</td> <td>   -0.124</td> <td> 0.901</td> <td>-4.25e+04</td> <td> 3.74e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                               <td>-2530.3335</td> <td> 2.04e+04</td> <td>   -0.124</td> <td> 0.901</td> <td>-4.25e+04</td> <td> 3.74e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                             <td>-2530.4432</td> <td> 2.04e+04</td> <td>   -0.124</td> <td> 0.901</td> <td>-4.25e+04</td> <td> 3.74e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                  <td>   53.0887</td> <td>  413.861</td> <td>    0.128</td> <td> 0.898</td> <td> -758.258</td> <td>  864.435</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                <td>   49.2811</td> <td>  407.378</td> <td>    0.121</td> <td> 0.904</td> <td> -749.355</td> <td>  847.917</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>   <td>   -0.5318</td> <td>    4.139</td> <td>   -0.128</td> <td> 0.898</td> <td>   -8.646</td> <td>    7.582</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th> <td>   -0.4933</td> <td>    4.074</td> <td>   -0.121</td> <td> 0.904</td> <td>   -8.480</td> <td>    7.494</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>     <td>   -0.5307</td> <td>    4.139</td> <td>   -0.128</td> <td> 0.898</td> <td>   -8.644</td> <td>    7.583</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>   <td>   -0.4927</td> <td>    4.074</td> <td>   -0.121</td> <td> 0.904</td> <td>   -8.479</td> <td>    7.494</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>4736.948</td> <th>  Durbin-Watson:     </th> <td>   1.414</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 956.795</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>           <td> 0.878</td>  <th>  Prob(JB):          </th> <td>1.72e-208</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>       <td> 1.802</td>  <th>  Cond. No.          </th> <td>3.58e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                              &  Warmth\\_actual  & \\textbf{  R-squared:         } &     0.007   \\\\\n",
                            "\\textbf{Model:}                                      &       OLS        & \\textbf{  Adj. R-squared:    } &     0.005   \\\\\n",
                            "\\textbf{Method:}                                     &  Least Squares   & \\textbf{  F-statistic:       } &     2.955   \\\\\n",
                            "\\textbf{Date:}                                       & Fri, 17 Nov 2023 & \\textbf{  Prob (F-statistic):} &  0.000408   \\\\\n",
                            "\\textbf{Time:}                                       &     09:32:12     & \\textbf{  Log-Likelihood:    } &   -3214.4   \\\\\n",
                            "\\textbf{No. Observations:}                           &        5084      & \\textbf{  AIC:               } &     6455.   \\\\\n",
                            "\\textbf{Df Residuals:}                               &        5071      & \\textbf{  BIC:               } &     6540.   \\\\\n",
                            "\\textbf{Df Model:}                                   &          12      & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                            &    nonrobust     & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                              &   -2530.2500  &     2.04e+04     &    -0.124  &         0.901        &    -4.25e+04    &     3.74e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                               &   -2530.3945  &     2.04e+04     &    -0.124  &         0.901        &    -4.25e+04    &     3.74e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                &   -2530.4341  &     2.04e+04     &    -0.124  &         0.901        &    -4.25e+04    &     3.74e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}               &      50.6766  &      407.346     &     0.124  &         0.901        &     -747.898    &      849.251     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                 &      50.5947  &      407.339     &     0.124  &         0.901        &     -747.965    &      849.155     \\\\\n",
                            "\\textbf{Age\\_Older}                                  &   -2530.3020  &     2.04e+04     &    -0.124  &         0.901        &    -4.25e+04    &     3.74e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                  &   -2530.3335  &     2.04e+04     &    -0.124  &         0.901        &    -4.25e+04    &     3.74e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                &   -2530.4432  &     2.04e+04     &    -0.124  &         0.901        &    -4.25e+04    &     3.74e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                   &      53.0887  &      413.861     &     0.128  &         0.898        &     -758.258    &      864.435     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                 &      49.2811  &      407.378     &     0.121  &         0.904        &     -749.355    &      847.917     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}   &      -0.5318  &        4.139     &    -0.128  &         0.898        &       -8.646    &        7.582     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector} &      -0.4933  &        4.074     &    -0.121  &         0.904        &       -8.480    &        7.494     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}     &      -0.5307  &        4.139     &    -0.128  &         0.898        &       -8.644    &        7.583     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}   &      -0.4927  &        4.074     &    -0.121  &         0.904        &       -8.479    &        7.494     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 4736.948 & \\textbf{  Durbin-Watson:     } &     1.414  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } &   956.795  \\\\\n",
                            "\\textbf{Skew:}          &   0.878  & \\textbf{  Prob(JB):          } & 1.72e-208  \\\\\n",
                            "\\textbf{Kurtosis:}      &   1.802  & \\textbf{  Cond. No.          } &  3.58e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 1.05e-24. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                            OLS Regression Results                            \n",
                            "==============================================================================\n",
                            "Dep. Variable:          Warmth_actual   R-squared:                       0.007\n",
                            "Model:                            OLS   Adj. R-squared:                  0.005\n",
                            "Method:                 Least Squares   F-statistic:                     2.955\n",
                            "Date:                Fri, 17 Nov 2023   Prob (F-statistic):           0.000408\n",
                            "Time:                        09:32:12   Log-Likelihood:                -3214.4\n",
                            "No. Observations:                5084   AIC:                             6455.\n",
                            "Df Residuals:                    5071   BIC:                             6540.\n",
                            "Df Model:                          12                                         \n",
                            "Covariance Type:            nonrobust                                         \n",
                            "===========================================================================================================\n",
                            "                                              coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "-----------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                           -2530.2500   2.04e+04     -0.124      0.901   -4.25e+04    3.74e+04\n",
                            "Gender_Mixed                            -2530.3945   2.04e+04     -0.124      0.901   -4.25e+04    3.74e+04\n",
                            "Gender_Male                             -2530.4341   2.04e+04     -0.124      0.901   -4.25e+04    3.74e+04\n",
                            "Gender_Female_% per Sector                 50.6766    407.346      0.124      0.901    -747.898     849.251\n",
                            "Gender_Male_% per Sector                   50.5947    407.339      0.124      0.901    -747.965     849.155\n",
                            "Age_Older                               -2530.3020   2.04e+04     -0.124      0.901   -4.25e+04    3.74e+04\n",
                            "Age_Mixed                               -2530.3335   2.04e+04     -0.124      0.901   -4.25e+04    3.74e+04\n",
                            "Age_Younger                             -2530.4432   2.04e+04     -0.124      0.901   -4.25e+04    3.74e+04\n",
                            "Age_Older_% per Sector                     53.0887    413.861      0.128      0.898    -758.258     864.435\n",
                            "Age_Younger_% per Sector                   49.2811    407.378      0.121      0.904    -749.355     847.917\n",
                            "Interaction_Female_Older_% per Sector      -0.5318      4.139     -0.128      0.898      -8.646       7.582\n",
                            "Interaction_Female_Younger_% per Sector    -0.4933      4.074     -0.121      0.904      -8.480       7.494\n",
                            "Interaction_Male_Older_% per Sector        -0.5307      4.139     -0.128      0.898      -8.644       7.583\n",
                            "Interaction_Male_Younger_% per Sector      -0.4927      4.074     -0.121      0.904      -8.479       7.494\n",
                            "==============================================================================\n",
                            "Omnibus:                     4736.948   Durbin-Watson:                   1.414\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              956.795\n",
                            "Skew:                           0.878   Prob(JB):                    1.72e-208\n",
                            "Kurtosis:                       1.802   Cond. No.                     3.58e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Warmth']['Unbiased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>    <td>Warmth_predicted</td> <th>  R-squared:         </th> <td>   0.006</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.752</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>             <td>Fri, 17 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>0.000986</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                 <td>09:32:12</td>     <th>  Log-Likelihood:    </th> <td> -3100.4</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>      <td>  5084</td>      <th>  AIC:               </th> <td>   6227.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>          <td>  5071</td>      <th>  BIC:               </th> <td>   6312.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                     <td></td>                        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                           <td>-5339.8301</td> <td> 1.99e+04</td> <td>   -0.268</td> <td> 0.789</td> <td>-4.44e+04</td> <td> 3.37e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                            <td>-5339.9384</td> <td> 1.99e+04</td> <td>   -0.268</td> <td> 0.789</td> <td>-4.44e+04</td> <td> 3.37e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                             <td>-5339.9839</td> <td> 1.99e+04</td> <td>   -0.268</td> <td> 0.789</td> <td>-4.44e+04</td> <td> 3.37e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>              <td>  107.2746</td> <td>  398.314</td> <td>    0.269</td> <td> 0.788</td> <td> -673.593</td> <td>  888.142</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                <td>  106.6233</td> <td>  398.307</td> <td>    0.268</td> <td> 0.789</td> <td> -674.230</td> <td>  887.476</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                               <td>-5339.9185</td> <td> 1.99e+04</td> <td>   -0.268</td> <td> 0.789</td> <td>-4.44e+04</td> <td> 3.37e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                               <td>-5339.9076</td> <td> 1.99e+04</td> <td>   -0.268</td> <td> 0.789</td> <td>-4.44e+04</td> <td> 3.37e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                             <td>-5339.9264</td> <td> 1.99e+04</td> <td>   -0.268</td> <td> 0.789</td> <td>-4.44e+04</td> <td> 3.37e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                  <td>  109.7135</td> <td>  404.685</td> <td>    0.271</td> <td> 0.786</td> <td> -683.643</td> <td>  903.070</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                <td>  105.9979</td> <td>  398.345</td> <td>    0.266</td> <td> 0.790</td> <td> -674.930</td> <td>  886.926</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>   <td>   -1.1019</td> <td>    4.047</td> <td>   -0.272</td> <td> 0.785</td> <td>   -9.036</td> <td>    6.832</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th> <td>   -1.0647</td> <td>    3.984</td> <td>   -0.267</td> <td> 0.789</td> <td>   -8.874</td> <td>    6.745</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>     <td>   -1.0954</td> <td>    4.047</td> <td>   -0.271</td> <td> 0.787</td> <td>   -9.029</td> <td>    6.838</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>   <td>   -1.0582</td> <td>    3.984</td> <td>   -0.266</td> <td> 0.791</td> <td>   -8.868</td> <td>    6.751</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>1634.186</td> <th>  Durbin-Watson:     </th> <td>   1.546</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1041.594</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>           <td> 0.995</td>  <th>  Prob(JB):          </th> <td>6.62e-227</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>       <td> 2.020</td>  <th>  Cond. No.          </th> <td>3.58e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                              & Warmth\\_predicted & \\textbf{  R-squared:         } &     0.006   \\\\\n",
                            "\\textbf{Model:}                                      &        OLS        & \\textbf{  Adj. R-squared:    } &     0.004   \\\\\n",
                            "\\textbf{Method:}                                     &   Least Squares   & \\textbf{  F-statistic:       } &     2.752   \\\\\n",
                            "\\textbf{Date:}                                       &  Fri, 17 Nov 2023 & \\textbf{  Prob (F-statistic):} &  0.000986   \\\\\n",
                            "\\textbf{Time:}                                       &      09:32:12     & \\textbf{  Log-Likelihood:    } &   -3100.4   \\\\\n",
                            "\\textbf{No. Observations:}                           &         5084      & \\textbf{  AIC:               } &     6227.   \\\\\n",
                            "\\textbf{Df Residuals:}                               &         5071      & \\textbf{  BIC:               } &     6312.   \\\\\n",
                            "\\textbf{Df Model:}                                   &           12      & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                            &     nonrobust     & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                              &   -5339.8301  &     1.99e+04     &    -0.268  &         0.789        &    -4.44e+04    &     3.37e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                               &   -5339.9384  &     1.99e+04     &    -0.268  &         0.789        &    -4.44e+04    &     3.37e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                &   -5339.9839  &     1.99e+04     &    -0.268  &         0.789        &    -4.44e+04    &     3.37e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}               &     107.2746  &      398.314     &     0.269  &         0.788        &     -673.593    &      888.142     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                 &     106.6233  &      398.307     &     0.268  &         0.789        &     -674.230    &      887.476     \\\\\n",
                            "\\textbf{Age\\_Older}                                  &   -5339.9185  &     1.99e+04     &    -0.268  &         0.789        &    -4.44e+04    &     3.37e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                  &   -5339.9076  &     1.99e+04     &    -0.268  &         0.789        &    -4.44e+04    &     3.37e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                &   -5339.9264  &     1.99e+04     &    -0.268  &         0.789        &    -4.44e+04    &     3.37e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                   &     109.7135  &      404.685     &     0.271  &         0.786        &     -683.643    &      903.070     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                 &     105.9979  &      398.345     &     0.266  &         0.790        &     -674.930    &      886.926     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}   &      -1.1019  &        4.047     &    -0.272  &         0.785        &       -9.036    &        6.832     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector} &      -1.0647  &        3.984     &    -0.267  &         0.789        &       -8.874    &        6.745     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}     &      -1.0954  &        4.047     &    -0.271  &         0.787        &       -9.029    &        6.838     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}   &      -1.0582  &        3.984     &    -0.266  &         0.791        &       -8.868    &        6.751     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 1634.186 & \\textbf{  Durbin-Watson:     } &     1.546  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } &  1041.594  \\\\\n",
                            "\\textbf{Skew:}          &   0.995  & \\textbf{  Prob(JB):          } & 6.62e-227  \\\\\n",
                            "\\textbf{Kurtosis:}      &   2.020  & \\textbf{  Cond. No.          } &  3.58e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 1.05e-24. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                            OLS Regression Results                            \n",
                            "==============================================================================\n",
                            "Dep. Variable:       Warmth_predicted   R-squared:                       0.006\n",
                            "Model:                            OLS   Adj. R-squared:                  0.004\n",
                            "Method:                 Least Squares   F-statistic:                     2.752\n",
                            "Date:                Fri, 17 Nov 2023   Prob (F-statistic):           0.000986\n",
                            "Time:                        09:32:12   Log-Likelihood:                -3100.4\n",
                            "No. Observations:                5084   AIC:                             6227.\n",
                            "Df Residuals:                    5071   BIC:                             6312.\n",
                            "Df Model:                          12                                         \n",
                            "Covariance Type:            nonrobust                                         \n",
                            "===========================================================================================================\n",
                            "                                              coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "-----------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                           -5339.8301   1.99e+04     -0.268      0.789   -4.44e+04    3.37e+04\n",
                            "Gender_Mixed                            -5339.9384   1.99e+04     -0.268      0.789   -4.44e+04    3.37e+04\n",
                            "Gender_Male                             -5339.9839   1.99e+04     -0.268      0.789   -4.44e+04    3.37e+04\n",
                            "Gender_Female_% per Sector                107.2746    398.314      0.269      0.788    -673.593     888.142\n",
                            "Gender_Male_% per Sector                  106.6233    398.307      0.268      0.789    -674.230     887.476\n",
                            "Age_Older                               -5339.9185   1.99e+04     -0.268      0.789   -4.44e+04    3.37e+04\n",
                            "Age_Mixed                               -5339.9076   1.99e+04     -0.268      0.789   -4.44e+04    3.37e+04\n",
                            "Age_Younger                             -5339.9264   1.99e+04     -0.268      0.789   -4.44e+04    3.37e+04\n",
                            "Age_Older_% per Sector                    109.7135    404.685      0.271      0.786    -683.643     903.070\n",
                            "Age_Younger_% per Sector                  105.9979    398.345      0.266      0.790    -674.930     886.926\n",
                            "Interaction_Female_Older_% per Sector      -1.1019      4.047     -0.272      0.785      -9.036       6.832\n",
                            "Interaction_Female_Younger_% per Sector    -1.0647      3.984     -0.267      0.789      -8.874       6.745\n",
                            "Interaction_Male_Older_% per Sector        -1.0954      4.047     -0.271      0.787      -9.029       6.838\n",
                            "Interaction_Male_Younger_% per Sector      -1.0582      3.984     -0.266      0.791      -8.868       6.751\n",
                            "==============================================================================\n",
                            "Omnibus:                     1634.186   Durbin-Watson:                   1.546\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1041.594\n",
                            "Skew:                           0.995   Prob(JB):                    6.62e-227\n",
                            "Kurtosis:                       2.020   Cond. No.                     3.58e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Warmth']['Biased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>    <td>Competence_actual</td> <th>  R-squared:         </th> <td>   0.011</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.009</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   4.787</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>             <td>Fri, 17 Nov 2023</td>  <th>  Prob (F-statistic):</th> <td>7.34e-08</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                 <td>09:32:12</td>      <th>  Log-Likelihood:    </th> <td> -3660.8</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>      <td>  5084</td>       <th>  AIC:               </th> <td>   7348.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>          <td>  5071</td>       <th>  BIC:               </th> <td>   7433.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>              <td>    12</td>       <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                     <td></td>                        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                           <td>  853.6003</td> <td> 2.22e+04</td> <td>    0.038</td> <td> 0.969</td> <td>-4.27e+04</td> <td> 4.44e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                            <td>  853.2809</td> <td> 2.22e+04</td> <td>    0.038</td> <td> 0.969</td> <td>-4.27e+04</td> <td> 4.44e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                             <td>  853.1801</td> <td> 2.22e+04</td> <td>    0.038</td> <td> 0.969</td> <td>-4.27e+04</td> <td> 4.44e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>              <td>  -17.7824</td> <td>  444.736</td> <td>   -0.040</td> <td> 0.968</td> <td> -889.656</td> <td>  854.092</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                <td>  -16.7838</td> <td>  444.727</td> <td>   -0.038</td> <td> 0.970</td> <td> -888.642</td> <td>  855.074</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                               <td>  853.4807</td> <td> 2.22e+04</td> <td>    0.038</td> <td> 0.969</td> <td>-4.27e+04</td> <td> 4.44e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                               <td>  853.3418</td> <td> 2.22e+04</td> <td>    0.038</td> <td> 0.969</td> <td>-4.27e+04</td> <td> 4.44e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                             <td>  853.2388</td> <td> 2.22e+04</td> <td>    0.038</td> <td> 0.969</td> <td>-4.27e+04</td> <td> 4.44e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                  <td>  -12.7993</td> <td>  451.849</td> <td>   -0.028</td> <td> 0.977</td> <td> -898.618</td> <td>  873.019</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                <td>  -18.1892</td> <td>  444.770</td> <td>   -0.041</td> <td> 0.967</td> <td> -890.130</td> <td>  853.752</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>   <td>    0.1349</td> <td>    4.519</td> <td>    0.030</td> <td> 0.976</td> <td>   -8.724</td> <td>    8.994</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th> <td>    0.1893</td> <td>    4.448</td> <td>    0.043</td> <td> 0.966</td> <td>   -8.531</td> <td>    8.909</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>     <td>    0.1253</td> <td>    4.519</td> <td>    0.028</td> <td> 0.978</td> <td>   -8.733</td> <td>    8.984</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>   <td>    0.1791</td> <td>    4.448</td> <td>    0.040</td> <td> 0.968</td> <td>   -8.540</td> <td>    8.899</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>18116.832</td> <th>  Durbin-Watson:     </th> <td>   1.226</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 811.414</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>           <td>-0.022</td>   <th>  Prob(JB):          </th> <td>6.36e-177</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>       <td> 1.043</td>   <th>  Cond. No.          </th> <td>3.58e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                              & Competence\\_actual & \\textbf{  R-squared:         } &     0.011   \\\\\n",
                            "\\textbf{Model:}                                      &        OLS         & \\textbf{  Adj. R-squared:    } &     0.009   \\\\\n",
                            "\\textbf{Method:}                                     &   Least Squares    & \\textbf{  F-statistic:       } &     4.787   \\\\\n",
                            "\\textbf{Date:}                                       &  Fri, 17 Nov 2023  & \\textbf{  Prob (F-statistic):} &  7.34e-08   \\\\\n",
                            "\\textbf{Time:}                                       &      09:32:12      & \\textbf{  Log-Likelihood:    } &   -3660.8   \\\\\n",
                            "\\textbf{No. Observations:}                           &         5084       & \\textbf{  AIC:               } &     7348.   \\\\\n",
                            "\\textbf{Df Residuals:}                               &         5071       & \\textbf{  BIC:               } &     7433.   \\\\\n",
                            "\\textbf{Df Model:}                                   &           12       & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                            &     nonrobust      & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                              &     853.6003  &     2.22e+04     &     0.038  &         0.969        &    -4.27e+04    &     4.44e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                               &     853.2809  &     2.22e+04     &     0.038  &         0.969        &    -4.27e+04    &     4.44e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                &     853.1801  &     2.22e+04     &     0.038  &         0.969        &    -4.27e+04    &     4.44e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}               &     -17.7824  &      444.736     &    -0.040  &         0.968        &     -889.656    &      854.092     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                 &     -16.7838  &      444.727     &    -0.038  &         0.970        &     -888.642    &      855.074     \\\\\n",
                            "\\textbf{Age\\_Older}                                  &     853.4807  &     2.22e+04     &     0.038  &         0.969        &    -4.27e+04    &     4.44e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                  &     853.3418  &     2.22e+04     &     0.038  &         0.969        &    -4.27e+04    &     4.44e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                &     853.2388  &     2.22e+04     &     0.038  &         0.969        &    -4.27e+04    &     4.44e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                   &     -12.7993  &      451.849     &    -0.028  &         0.977        &     -898.618    &      873.019     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                 &     -18.1892  &      444.770     &    -0.041  &         0.967        &     -890.130    &      853.752     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}   &       0.1349  &        4.519     &     0.030  &         0.976        &       -8.724    &        8.994     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector} &       0.1893  &        4.448     &     0.043  &         0.966        &       -8.531    &        8.909     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}     &       0.1253  &        4.519     &     0.028  &         0.978        &       -8.733    &        8.984     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}   &       0.1791  &        4.448     &     0.040  &         0.968        &       -8.540    &        8.899     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 18116.832 & \\textbf{  Durbin-Watson:     } &     1.226  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } &   811.414  \\\\\n",
                            "\\textbf{Skew:}          &   -0.022  & \\textbf{  Prob(JB):          } & 6.36e-177  \\\\\n",
                            "\\textbf{Kurtosis:}      &    1.043  & \\textbf{  Cond. No.          } &  3.58e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 1.05e-24. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                            OLS Regression Results                            \n",
                            "==============================================================================\n",
                            "Dep. Variable:      Competence_actual   R-squared:                       0.011\n",
                            "Model:                            OLS   Adj. R-squared:                  0.009\n",
                            "Method:                 Least Squares   F-statistic:                     4.787\n",
                            "Date:                Fri, 17 Nov 2023   Prob (F-statistic):           7.34e-08\n",
                            "Time:                        09:32:12   Log-Likelihood:                -3660.8\n",
                            "No. Observations:                5084   AIC:                             7348.\n",
                            "Df Residuals:                    5071   BIC:                             7433.\n",
                            "Df Model:                          12                                         \n",
                            "Covariance Type:            nonrobust                                         \n",
                            "===========================================================================================================\n",
                            "                                              coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "-----------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                             853.6003   2.22e+04      0.038      0.969   -4.27e+04    4.44e+04\n",
                            "Gender_Mixed                              853.2809   2.22e+04      0.038      0.969   -4.27e+04    4.44e+04\n",
                            "Gender_Male                               853.1801   2.22e+04      0.038      0.969   -4.27e+04    4.44e+04\n",
                            "Gender_Female_% per Sector                -17.7824    444.736     -0.040      0.968    -889.656     854.092\n",
                            "Gender_Male_% per Sector                  -16.7838    444.727     -0.038      0.970    -888.642     855.074\n",
                            "Age_Older                                 853.4807   2.22e+04      0.038      0.969   -4.27e+04    4.44e+04\n",
                            "Age_Mixed                                 853.3418   2.22e+04      0.038      0.969   -4.27e+04    4.44e+04\n",
                            "Age_Younger                               853.2388   2.22e+04      0.038      0.969   -4.27e+04    4.44e+04\n",
                            "Age_Older_% per Sector                    -12.7993    451.849     -0.028      0.977    -898.618     873.019\n",
                            "Age_Younger_% per Sector                  -18.1892    444.770     -0.041      0.967    -890.130     853.752\n",
                            "Interaction_Female_Older_% per Sector       0.1349      4.519      0.030      0.976      -8.724       8.994\n",
                            "Interaction_Female_Younger_% per Sector     0.1893      4.448      0.043      0.966      -8.531       8.909\n",
                            "Interaction_Male_Older_% per Sector         0.1253      4.519      0.028      0.978      -8.733       8.984\n",
                            "Interaction_Male_Younger_% per Sector       0.1791      4.448      0.040      0.968      -8.540       8.899\n",
                            "==============================================================================\n",
                            "Omnibus:                    18116.832   Durbin-Watson:                   1.226\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              811.414\n",
                            "Skew:                          -0.022   Prob(JB):                    6.36e-177\n",
                            "Kurtosis:                       1.043   Cond. No.                     3.58e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Competence']['Unbiased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>    <td>Competence_predicted</td> <th>  R-squared:         </th> <td>   0.008</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                     <td>OLS</td>         <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>               <td>Least Squares</td>    <th>  F-statistic:       </th> <td>   3.263</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>               <td>Fri, 17 Nov 2023</td>   <th>  Prob (F-statistic):</th> <td>0.000104</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                   <td>09:32:12</td>       <th>  Log-Likelihood:    </th> <td> -3668.1</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>        <td>  5084</td>        <th>  AIC:               </th> <td>   7362.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>            <td>  5071</td>        <th>  BIC:               </th> <td>   7447.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>                <td>    12</td>        <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>        <td>nonrobust</td>      <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                     <td></td>                        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                           <td>   4.3e+04</td> <td> 2.23e+04</td> <td>    1.931</td> <td> 0.054</td> <td> -653.416</td> <td> 8.67e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                            <td>   4.3e+04</td> <td> 2.23e+04</td> <td>    1.931</td> <td> 0.054</td> <td> -653.534</td> <td> 8.67e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                             <td>   4.3e+04</td> <td> 2.23e+04</td> <td>    1.931</td> <td> 0.054</td> <td> -653.588</td> <td> 8.67e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>              <td> -860.6247</td> <td>  445.372</td> <td>   -1.932</td> <td> 0.053</td> <td>-1733.745</td> <td>   12.496</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                <td> -859.8504</td> <td>  445.363</td> <td>   -1.931</td> <td> 0.054</td> <td>-1732.955</td> <td>   13.254</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                               <td>   4.3e+04</td> <td> 2.23e+04</td> <td>    1.931</td> <td> 0.054</td> <td> -653.512</td> <td> 8.67e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                               <td>   4.3e+04</td> <td> 2.23e+04</td> <td>    1.931</td> <td> 0.054</td> <td> -653.503</td> <td> 8.67e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                             <td>   4.3e+04</td> <td> 2.23e+04</td> <td>    1.931</td> <td> 0.054</td> <td> -653.524</td> <td> 8.67e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                  <td> -872.1487</td> <td>  452.495</td> <td>   -1.927</td> <td> 0.054</td> <td>-1759.234</td> <td>   14.937</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                <td> -859.7864</td> <td>  445.406</td> <td>   -1.930</td> <td> 0.054</td> <td>-1732.974</td> <td>   13.401</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>   <td>    8.7277</td> <td>    4.525</td> <td>    1.929</td> <td> 0.054</td> <td>   -0.144</td> <td>   17.599</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th> <td>    8.6043</td> <td>    4.454</td> <td>    1.932</td> <td> 0.053</td> <td>   -0.128</td> <td>   17.337</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>     <td>    8.7200</td> <td>    4.525</td> <td>    1.927</td> <td> 0.054</td> <td>   -0.151</td> <td>   17.591</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>   <td>    8.5962</td> <td>    4.454</td> <td>    1.930</td> <td> 0.054</td> <td>   -0.136</td> <td>   17.328</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>18014.541</td> <th>  Durbin-Watson:     </th> <td>   1.333</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 821.888</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>           <td>-0.058</td>   <th>  Prob(JB):          </th> <td>3.38e-179</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>       <td> 1.034</td>   <th>  Cond. No.          </th> <td>3.58e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                              & Competence\\_predicted & \\textbf{  R-squared:         } &     0.008   \\\\\n",
                            "\\textbf{Model:}                                      &          OLS          & \\textbf{  Adj. R-squared:    } &     0.005   \\\\\n",
                            "\\textbf{Method:}                                     &     Least Squares     & \\textbf{  F-statistic:       } &     3.263   \\\\\n",
                            "\\textbf{Date:}                                       &    Fri, 17 Nov 2023   & \\textbf{  Prob (F-statistic):} &  0.000104   \\\\\n",
                            "\\textbf{Time:}                                       &        09:32:12       & \\textbf{  Log-Likelihood:    } &   -3668.1   \\\\\n",
                            "\\textbf{No. Observations:}                           &           5084        & \\textbf{  AIC:               } &     7362.   \\\\\n",
                            "\\textbf{Df Residuals:}                               &           5071        & \\textbf{  BIC:               } &     7447.   \\\\\n",
                            "\\textbf{Df Model:}                                   &             12        & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                            &       nonrobust       & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                              &      4.3e+04  &     2.23e+04     &     1.931  &         0.054        &     -653.416    &     8.67e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                               &      4.3e+04  &     2.23e+04     &     1.931  &         0.054        &     -653.534    &     8.67e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                &      4.3e+04  &     2.23e+04     &     1.931  &         0.054        &     -653.588    &     8.67e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}               &    -860.6247  &      445.372     &    -1.932  &         0.053        &    -1733.745    &       12.496     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                 &    -859.8504  &      445.363     &    -1.931  &         0.054        &    -1732.955    &       13.254     \\\\\n",
                            "\\textbf{Age\\_Older}                                  &      4.3e+04  &     2.23e+04     &     1.931  &         0.054        &     -653.512    &     8.67e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                  &      4.3e+04  &     2.23e+04     &     1.931  &         0.054        &     -653.503    &     8.67e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                &      4.3e+04  &     2.23e+04     &     1.931  &         0.054        &     -653.524    &     8.67e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                   &    -872.1487  &      452.495     &    -1.927  &         0.054        &    -1759.234    &       14.937     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                 &    -859.7864  &      445.406     &    -1.930  &         0.054        &    -1732.974    &       13.401     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}   &       8.7277  &        4.525     &     1.929  &         0.054        &       -0.144    &       17.599     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector} &       8.6043  &        4.454     &     1.932  &         0.053        &       -0.128    &       17.337     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}     &       8.7200  &        4.525     &     1.927  &         0.054        &       -0.151    &       17.591     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}   &       8.5962  &        4.454     &     1.930  &         0.054        &       -0.136    &       17.328     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 18014.541 & \\textbf{  Durbin-Watson:     } &     1.333  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } &   821.888  \\\\\n",
                            "\\textbf{Skew:}          &   -0.058  & \\textbf{  Prob(JB):          } & 3.38e-179  \\\\\n",
                            "\\textbf{Kurtosis:}      &    1.034  & \\textbf{  Cond. No.          } &  3.58e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 1.05e-24. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                             OLS Regression Results                             \n",
                            "================================================================================\n",
                            "Dep. Variable:     Competence_predicted   R-squared:                       0.008\n",
                            "Model:                              OLS   Adj. R-squared:                  0.005\n",
                            "Method:                   Least Squares   F-statistic:                     3.263\n",
                            "Date:                  Fri, 17 Nov 2023   Prob (F-statistic):           0.000104\n",
                            "Time:                          09:32:12   Log-Likelihood:                -3668.1\n",
                            "No. Observations:                  5084   AIC:                             7362.\n",
                            "Df Residuals:                      5071   BIC:                             7447.\n",
                            "Df Model:                            12                                         \n",
                            "Covariance Type:              nonrobust                                         \n",
                            "===========================================================================================================\n",
                            "                                              coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "-----------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                              4.3e+04   2.23e+04      1.931      0.054    -653.416    8.67e+04\n",
                            "Gender_Mixed                               4.3e+04   2.23e+04      1.931      0.054    -653.534    8.67e+04\n",
                            "Gender_Male                                4.3e+04   2.23e+04      1.931      0.054    -653.588    8.67e+04\n",
                            "Gender_Female_% per Sector               -860.6247    445.372     -1.932      0.053   -1733.745      12.496\n",
                            "Gender_Male_% per Sector                 -859.8504    445.363     -1.931      0.054   -1732.955      13.254\n",
                            "Age_Older                                  4.3e+04   2.23e+04      1.931      0.054    -653.512    8.67e+04\n",
                            "Age_Mixed                                  4.3e+04   2.23e+04      1.931      0.054    -653.503    8.67e+04\n",
                            "Age_Younger                                4.3e+04   2.23e+04      1.931      0.054    -653.524    8.67e+04\n",
                            "Age_Older_% per Sector                   -872.1487    452.495     -1.927      0.054   -1759.234      14.937\n",
                            "Age_Younger_% per Sector                 -859.7864    445.406     -1.930      0.054   -1732.974      13.401\n",
                            "Interaction_Female_Older_% per Sector       8.7277      4.525      1.929      0.054      -0.144      17.599\n",
                            "Interaction_Female_Younger_% per Sector     8.6043      4.454      1.932      0.053      -0.128      17.337\n",
                            "Interaction_Male_Older_% per Sector         8.7200      4.525      1.927      0.054      -0.151      17.591\n",
                            "Interaction_Male_Younger_% per Sector       8.5962      4.454      1.930      0.054      -0.136      17.328\n",
                            "==============================================================================\n",
                            "Omnibus:                    18014.541   Durbin-Watson:                   1.333\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              821.888\n",
                            "Skew:                          -0.058   Prob(JB):                    3.38e-179\n",
                            "Kurtosis:                       1.034   Cond. No.                     3.58e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 1.05e-24. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Competence']['Biased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9202851",
            "metadata": {},
            "source": [
                "## Make RandomForestRegressor Classifier\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dcf1e9cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_final_indiv_and_aggr_preds(estimator, X):\n",
                "    pred = estimator.predict(X)\n",
                "    indiv_pred = [tree.predict(X) for tree in estimator.estimators_]\n",
                "    aggr_pred = np.mean(indiv_pred, axis=0)\n",
                "\n",
                "    return pred, indiv_pred, aggr_pred\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50385c5e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_randomforest_instrumental_variable_estimator(df_jobs, cols_to_compare=None, text_col=None, n_trees=None):\n",
                "\n",
                "    if cols_to_compare is None:\n",
                "        cols_to_compare = ['Warmth_actual', 'Warmth_predicted', 'Competence_actual', 'Competence_predicted']\n",
                "    if text_col is None:\n",
                "        text_col = 'Job Description spacy_sentencized'\n",
                "    if n_trees is None:\n",
                "        n_trees = 100\n",
                "    cols_dict = defaultdict()\n",
                "    train_ratio = 0.75\n",
                "    test_ratio = 0.10\n",
                "    validation_ratio = 0.15\n",
                "    test_split = test_size = 1 - train_ratio\n",
                "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "\n",
                "    # Make df_jobs_unlabeled\n",
                "    df_jobs_unlabeled = df_jobs.loc[\n",
                "        (df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_unlabeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_unlabeled = df_jobs_unlabeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_unlabeled of length: {len(df_jobs_unlabeled)}')\n",
                "\n",
                "    # Make df_jobs_labeled\n",
                "    df_jobs_labeled = df_jobs.loc[\n",
                "        (~df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_labeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_labeled = df_jobs_labeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_labeled of length: {len(df_jobs_labeled)}')\n",
                "\n",
                "    # Make df labels dict\n",
                "    df_add_preds_dict = {\n",
                "        'labeled': df_jobs_labeled,\n",
                "        'unlabeled': df_jobs_unlabeled\n",
                "    }\n",
                "\n",
                "    # Split data\n",
                "    print('Splitting data...')\n",
                "    train, test = train_test_split(\n",
                "        df_jobs_labeled, train_size=1-test_split, test_size=test_split, random_state=random_state\n",
                "    )\n",
                "    print(f'Length of train dataset: {len(train)}')\n",
                "    print(f'Length of test dataset: {len(test)}')\n",
                "    cols_dict = {\n",
                "        'train': train, 'test': test,\n",
                "    }\n",
                "\n",
                "    for col in tqdm.tqdm(analysis_columns):\n",
                "        assert col in df_jobs_labeled.columns, f'{col} column not found in df_jobs_labeled'\n",
                "        print('='*20)\n",
                "        print(f'Training on {col}...')\n",
                "\n",
                "        X_train = np.array(list(train[text_col].astype('str').values))\n",
                "        y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_test = np.array(list(test[text_col].astype('str').values))\n",
                "        y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_labeled = np.array(list(df_jobs_labeled[text_col].astype('str').values))\n",
                "        y_labeled = column_or_1d(df_jobs_labeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_unlabeled = np.array(list(df_jobs_unlabeled[text_col].astype('str').values))\n",
                "        y_unlabeled = column_or_1d(df_jobs_unlabeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        # Vectorize using FeatueUnion\n",
                "        print(f'Vectorizing using {vectorizers_list[-1].__class__.__name__}...')\n",
                "        vectorizer = vectorizers_list[-1]\n",
                "        X_train = vectorizer.fit_transform(X_train)\n",
                "        X_test = vectorizer.transform(X_test)\n",
                "        X_labeled = vectorizer.transform(X_labeled)\n",
                "        X_unlabeled = vectorizer.transform(X_unlabeled)\n",
                "\n",
                "        # Train using RandomForestRegressor\n",
                "        print('Training using RandomForestRegressor...')\n",
                "        estimator = RandomForestRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=n_jobs)\n",
                "        estimator.fit(X_train, y_train)\n",
                "\n",
                "        # Get predictions\n",
                "        print('Getting predictions...')\n",
                "        y_train_pred, indiv_y_train_pred, aggr_y_train_pred = make_final_indiv_and_aggr_preds(estimator, X_train)\n",
                "        y_test_pred, indiv_y_test_pred, aggr_y_test_pred = make_final_indiv_and_aggr_preds(estimator, X_test)\n",
                "        y_labeled_pred, indiv_y_labeled_pred, aggr_y_labeled_pred = make_final_indiv_and_aggr_preds(estimator, X_labeled)\n",
                "        y_unlabeled_pred, indiv_y_unlabeled_pred, aggr_y_unlabeled_pred = make_final_indiv_and_aggr_preds(estimator, X_unlabeled)\n",
                "\n",
                "        # Make col dict\n",
                "        cols_dict[col] = {\n",
                "            'estimator': estimator, 'vectorizer': vectorizer,\n",
                "            'X_train': X_train, 'y_train': y_train, 'y_train_pred': y_train_pred,\n",
                "            'indiv_y_train_pred': indiv_y_train_pred, 'aggr_y_train_pred': aggr_y_train_pred,\n",
                "            'X_test': X_test, 'y_test': y_test, 'y_test_pred': y_test_pred,\n",
                "            'indiv_y_test_pred': indiv_y_test_pred, 'aggr_y_test_pred': aggr_y_test_pred,\n",
                "            'X_labeled': X_labeled, 'y_labeled': y_labeled, 'y_labeled_pred': y_labeled_pred,\n",
                "            'indiv_y_labeled_pred': indiv_y_labeled_pred, 'aggr_y_labeled_pred': aggr_y_labeled_pred,\n",
                "            'X_unlabeled': X_unlabeled, 'y_unlabeled': y_unlabeled, 'y_unlabeled_pred': y_unlabeled_pred,\n",
                "            'indiv_y_unlabeled_pred': indiv_y_unlabeled_pred, 'aggr_y_unlabeled_pred': aggr_y_unlabeled_pred,\n",
                "        }\n",
                "\n",
                "        # Add columns to df\n",
                "        for df_lab, df in tqdm.tqdm(df_add_preds_dict.items()):\n",
                "            df = pd.concat(\n",
                "                [\n",
                "                    df.reset_index(drop=True),\n",
                "                    pd.DataFrame(\n",
                "                        {\n",
                "                            f'{col}_{df_lab}_predicted': cols_dict[col][f'y_{df_lab}_pred'],\n",
                "                            f'{col}_aggr_{df_lab}_predicted': cols_dict[col][f'aggr_y_{df_lab}_pred'],\n",
                "                        }\n",
                "                    ).reset_index(drop=True),\n",
                "                    pd.DataFrame(cols_dict[col][f'indiv_y_{df_lab}_pred']).transpose().add_prefix(f'{col}_tree_').reset_index(drop=True)\n",
                "                ],\n",
                "                axis='columns'\n",
                "            )\n",
                "            cols_dict[col][f'df_jobs_{df_lab}'] = df\n",
                "\n",
                "        # Evaluate\n",
                "        print('Evaluating...')\n",
                "        score = estimator.score(X_test, y_test)\n",
                "        mae = mean_absolute_error(y_test, y_test_pred)\n",
                "        mse = mean_squared_error(y_test, y_test_pred)\n",
                "        rmse = np.sqrt(mse)\n",
                "        r2 = r2_score(y_test, y_test_pred)\n",
                "\n",
                "        print('-'*20)\n",
                "        print(f'Mean Absolute Error: {mae:3f}')\n",
                "        print(f'Mean Squared Error: {mse:3f}')\n",
                "        print(f'Root Mean Squared Error: {rmse:3f}')\n",
                "        print(f'R-squared (R^2) Score: {r2:3f}')\n",
                "        print('-'*20)\n",
                "\n",
                "    return n_trees, dict(cols_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14cc0d13",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_trees, cols_dict = get_randomforest_instrumental_variable_estimator(df_jobs, n_trees=100)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59b7ec3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3221c1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "list_columns = [c for c in df_jobs.columns if df_jobs[c].progress_apply(lambda x: isinstance(x, list)).any()]\n",
                "non_list_columns = [c for c in df_jobs.columns if not df_jobs[c].progress_apply(lambda x: isinstance(x, list)).any()]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a993ee38",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12167868",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e23e857",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled = cols_dict['Warmth']['df_jobs_labeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        cols_dict['Competence']['df_jobs_labeled'],\n",
                "        how='outer',\n",
                "        on=non_list_columns\n",
                "    ).dropna(axis='columns', how='all')\\\n",
                "        .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3b9868a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa150d05",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25567198",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eff0ccb5",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8597d57",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled = cols_dict['Warmth']['df_jobs_unlabeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "        .merge(\n",
                "            cols_dict['Competence']['df_jobs_unlabeled'],\n",
                "            how='outer',\n",
                "            on=non_list_columns\n",
                "        ).dropna(axis='columns', how='all')\\\n",
                "            .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "57fd9028",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb3b5c70",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa26dae",
            "metadata": {},
            "outputs": [],
            "source": [
                "train = cols_dict['train']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19353659",
            "metadata": {},
            "outputs": [],
            "source": [
                "train.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09a72253",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train = train.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2adff07d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "615db4ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "test = cols_dict['test']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a7cfb3f",
            "metadata": {},
            "outputs": [],
            "source": [
                "test.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dbf219e",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test = test\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        df_jobs_labeled,\n",
                "        how='inner',\n",
                "        on=non_list_columns\n",
                "    ).reset_index(drop=True)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b76d98f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "47f90db7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1a9e627",
            "metadata": {},
            "source": [
                "# Make instrumental Variable"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48060e42",
            "metadata": {},
            "source": [
                "### Make unbiased and biased models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0707e44c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction = pd.concat([df_jobs_labeled, df_jobs_unlabeled], axis='index')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8c27cbc",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1235f58a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "68f95899",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Biased model\n",
                "biased_post_classification_dict = defaultdict()\n",
                "for iv in tqdm.tqdm(ivs_dummy_perc_and_perc_interactions):\n",
                "    dv_names_dict_unlabeled_post_classification = compare_actual_and_predicted(\n",
                "        df_jobs_unlabeled, analysis_type='post_classification', iv_names=iv, print_enabled=False\n",
                "    )\n",
                "    biased_post_classification_dict[iv] = dv_names_dict_unlabeled_post_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae3352a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uniased model\n",
                "unbiased_post_classification_dict = defaultdict()\n",
                "for iv in tqdm.tqdm(ivs_dummy_perc_and_perc_interactions):\n",
                "    dv_names_dict_labeled_post_classification = compare_actual_and_predicted(\n",
                "        df_jobs_labeled, analysis_type='post_classification', iv_names=iv, print_enabled=False\n",
                "    )\n",
                "    unbiased_post_classification_dict[iv] = dv_names_dict_labeled_post_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1454b793",
            "metadata": {},
            "outputs": [],
            "source": [
                "unbiased_post_classification_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa12799",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get forest_iv results\n",
                "forest_iv_results_dict = defaultdict(lambda: defaultdict())\n",
                "forest_iv_params = {\n",
                "    # 'col': dv,\n",
                "    # 'var': iv,\n",
                "    # 'model_unbias': model_unbias,\n",
                "    'data_test': df_jobs_test,\n",
                "    'data_unlabel': df_jobs_for_correction,\n",
                "    # 'control': controls[:1],\n",
                "    'ntree': n_trees,\n",
                "    'iterative': True\n",
                "    # 'diagnostic': True,\n",
                "    # 'family': sm.families.Gaussian(link=sm.families.links.Identity()),\n",
                "    # 'select_method': 'optimal',\n",
                "    # 'method': 'Lasso',\n",
                "}\n",
                "\n",
                "for dv, iv in tqdm_product(dvs, ivs_dummy_perc_and_perc_interactions):\n",
                "    print('-'*20)\n",
                "    print(f'Analyzing {dv} with {iv}...')\n",
                "    forest_iv_params['col'] = dv\n",
                "    forest_iv_params['var'] = iv\n",
                "    forest_iv_params['model_unbias'] = unbiased_post_classification_dict[iv][dv]['Unbiased']['Results']\n",
                "\n",
                "    forest_iv_results_dict[dv][iv] = defaultdict()\n",
                "\n",
                "    results_IV, output, results  = forest_iv(**forest_iv_params)\n",
                "\n",
                "    forest_iv_results_dict[dv][iv]['Results_IV'] = results_IV\n",
                "    forest_iv_results_dict[dv][iv]['Output'] = output\n",
                "    forest_iv_results_dict[dv][iv]['Results'] = results\n",
                "\n",
                "# result = forest_iv(\n",
                "#     col=dv,\n",
                "#     data_test=df_jobs_test,\n",
                "#     data_unlabel=df_jobs_unlabeled,\n",
                "#     var=iv,\n",
                "#     control=controls[:1],\n",
                "#     ntree=n_trees,\n",
                "#     model_unbias=model_unbias,\n",
                "#     diagnostic=True,\n",
                "#     family=sm.families.Gaussian(link=sm.families.links.Identity()),\n",
                "#     select_method='optimal',\n",
                "#     method='Lasso',\n",
                "#     iterative=False\n",
                "# )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a63c9a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the critical value for a chi-squared distribution\n",
                "H_critical = scipy.stats.chi2.ppf(0.95, df=4)\n",
                "\n",
                "for dv, iv in tqdm_product(dvs, ivs_dummy_perc_and_perc_interactions):\n",
                "    # Get unbiased model\n",
                "    model_unbias = unbiased_post_classification_dict[iv][dv]['Unbiased']['Results']\n",
                "\n",
                "    # Get the unbiased coefficients\n",
                "    coef_unbiased = model_unbias.params\n",
                "\n",
                "    # Get results\n",
                "    results = forest_iv_results_dict[dv][iv]['Results']\n",
                "\n",
                "    # Calculate the squared bias for each beta\n",
                "    results['bias2'] = ((results[[beta for beta in results.columns if 'beta' in beta ]] - coef_unbiased) ** 2).sum(axis=1)\n",
                "\n",
                "    # Calculate the total variance\n",
                "    results['variance'] = (results[[se for se in results.columns if 'se' in se]] ** 2).sum(axis=1)\n",
                "\n",
                "    # Calculate the mean squared error (MSE)\n",
                "    results['mse'] = results['bias2'] + results['variance']\n",
                "\n",
                "    # Sort the DataFrame by MSE\n",
                "    results = results.sort_values(by='mse')\n",
                "\n",
                "    # Filter rows where Hotelling is less than H_critical and only keep the first row\n",
                "    filtered_results = results[(results['Hotelling'] < H_critical) & (results.index == results.index[0])]\n",
                "\n",
                "    # Display the filtered results\n",
                "    print(filtered_results[[beta for beta in results.columns if 'beta' in beta ]])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "biased_post_classification_dict[iv][dv]['Biased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_unbias.summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a50be1b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get valid instrumental variables from forest_iv_results_dict\n",
                "instrumental_variables = list(\n",
                "    {\n",
                "        instrument\n",
                "        for dv, iv in forest_iv_results_dict.items()\n",
                "        for k, v in iv.items()\n",
                "        for instrument in v['Output']['IVs']\n",
                "    }\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "instrumental_variables\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b60b30c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs_for_correction.loc[:,\n",
                "    (~df_jobs_for_correction.columns.str.contains('_tree_'))\n",
                "    | (df_jobs_for_correction.columns.isin(instrumental_variables))\n",
                "].reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9e5f3c1b",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "37533128",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a30d6c5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "iv = ivs_perc[0]\n",
                "col = dvs[0]\n",
                "for dv in dvs:\n",
                "    print(dv, iv)\n",
                "    results_IV = forest_iv_results_dict[dv][iv]['Results_IV']\n",
                "    print(results_IV.summary())\n",
                "    corrected_var = results_IV.predict(df_jobs[col])\n",
                "    print(corrected_var)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "efec800f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "# df_jobs.to_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "# df_jobs.to_csv(f'{df_save_dir}df_jobs_for_analysis.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ac17152",
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(f'Saving corrected df_jobs length {len(df_jobs)} to txt file.')\n",
                "# with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'w') as f:\n",
                "#     f.write(str(len(df_jobs)))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Automating_Equity1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
